{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "035941a3-fd58-48e6-a43a-fea00f672b41",
   "metadata": {},
   "source": [
    "**Simplified python reference implementation of hqq-qdora.**\n",
    "\n",
    "This nb only contains the final module, not the build up to it. For the full build up, see `python_hqq_qdora_v2.ipynb` and `python_hqq_qdora.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "225deadd-a13a-4146-bfb2-a6d91bf2b610",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import tensor, cat, int32, float16 as fp16\n",
    "from math import ceil\n",
    "\n",
    "from fastcore.basics import store_attr\n",
    "\n",
    "from hqq.core.quantize import Quantizer # optional; only for optimizing during quanting\n",
    "\n",
    "torch.set_printoptions(linewidth=200, precision=2, sci_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6f82477-707c-4358-8a2d-acf9202d4daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_abs_diff(a,b): return (a-b).abs().max()\n",
    "def assert_close(a,b): assert torch.isclose(a,b,atol=1e-2).all(), f'assert_close failed, max error = {max_abs_diff(a,b)}'\n",
    "def assert_somehow_close(a,b,max_err=0.12): assert torch.isclose(a,b,atol=max_err).all(), f'assert_somehow_close failed, max error = {max_abs_diff(a,b)}' # allow some error due to quanting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6c9d7e70-f910-4f1e-a241-5577c19a9824",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantedDoraModule(nn.Module):\n",
    "    def __init__(self, linear, bits, group_size, rank, alpha, compute_dtype=fp16, packed=True, optimized=True, group_size_zero=None, group_size_scale=None):\n",
    "        super().__init__()\n",
    "        # for quanting\n",
    "        store_attr('bits,group_size,packed,optimized,compute_dtype',self)\n",
    "        self.group_size_zero, self.group_size_scale = group_size_zero or 128, group_size_scale or 128 # hqq uses group size of 128 for zero & scale\n",
    "        self.quant(linear.weight.data)\n",
    "        # for dora\n",
    "        self.a = nn.Linear(linear.in_features, rank, bias=False, dtype=fp16)\n",
    "        self.b = nn.Linear(rank, linear.out_features, bias=False, dtype=fp16)\n",
    "        self.alpha = alpha\n",
    "        self.m = nn.Parameter(linear.weight.norm(p=2, dim=1))\n",
    "        # init a & b to 0 -- a should be inited differently, but for sake of simplicity, set it to 0 as well\n",
    "        self.a.weight.data.zero_()\n",
    "        self.b.weight.data.zero_()\n",
    "\n",
    "    @staticmethod\n",
    "    def pack(vals):\n",
    "        assert len(vals.shape)==2, 'Pass a 2d tensor'\n",
    "        for v in vals.flatten(): assert 0<=v.item()<=7 and v.item()//1==v.item(), f'Value {v} can\\'t be represented by 3 bits or is not an integer'    \n",
    "        rows, cols = vals.shape\n",
    "        n_packs = ceil(rows/10)\n",
    "        padded_vals = torch.zeros(n_packs*10, cols, dtype=int32)\n",
    "        padded_vals[:rows, :cols] = vals\n",
    "        packed = torch.zeros(n_packs, cols, dtype=int32)\n",
    "        for k in range(10): packed = (packed << 3) | padded_vals[k*n_packs:(k+1)*n_packs,:] # shift right 3 bits, then set last 3 bits to padded_vals[...,...]\n",
    "        return packed\n",
    "\n",
    "    @staticmethod\n",
    "    def unpack(packed, rows):\n",
    "        def bin_to_dec(b3,b2,b1): return 4*b3 + 2*b2 + b1\n",
    "        assert len(packed.shape)==2 and packed.dtype==int32, 'Pass a 2d tensor of int32s'\n",
    "        n_packs, cols = packed.shape\n",
    "        padded_vals = torch.zeros(n_packs*10, cols, dtype=int32)\n",
    "        for k_up, k_down in zip(range(10), reversed(range(10))): # top-most 3bits vals (k_up=0) are most right-shifted (k_down=9)\n",
    "            padded_vals[k_down*n_packs:(k_down+1)*n_packs,:] = ((packed >> (3*k_up)) & 0b111) # righ-shift 3*k_up times, so last 3 bits are those we want; then only select those via 0b111            \n",
    "        return padded_vals[:rows,:]\n",
    "    \n",
    "    @staticmethod\n",
    "    def _quant(data, group_size, bits=3, packed=True, optimize=True):\n",
    "        assert data.numel()%group_size==0, f'group_size {group_size} can\\'t evenly split the data (numel = {data.numel()})'\n",
    "        data = data.float().reshape(group_size,-1)\n",
    "        \n",
    "        min_, max_ = data.min(axis=0, keepdim=True).values, data.max(axis=0, keepdim=True).values\n",
    "    \n",
    "        scale = (2**bits-1) / (max_-min_) # note: hqq clamp to 2e4 to avoid half-precision problems, let's ignore that for now\n",
    "        zero = -min_ * scale\n",
    "    \n",
    "        if optimize: data, scale, zero = Quantizer.optimize_weights(data, scale, zero, min_max=[0, 2**bits-1])\n",
    "        else: data = (data * scale + zero).round()\n",
    "\n",
    "        if packed: data = QuantedDoraModule.pack(data)\n",
    "        return data, zero, 1/scale # invert scale, so in dequanting we multiply instead of divide \n",
    "\n",
    "    @staticmethod\n",
    "    def _dequant(data, zero, scale, shape, group_size, packed=True):\n",
    "        if packed: data = QuantedDoraModule.unpack(data, rows=group_size)\n",
    "        data = (data-zero)*scale\n",
    "        return data.reshape(shape)\n",
    "\n",
    "    def quant(self, data):\n",
    "        qdata,  zero       , scale        = self._quant(data,  self.group_size,       self.bits, self.packed, self.optimized)\n",
    "        qzero,  zeros_zero , zeros_scale  = self._quant(zero,  self.group_size_zero,  self.bits, self.packed, False)\n",
    "        qscale, scales_zero, scales_scale = self._quant(scale, self.group_size_scale, self.bits, self.packed, False)\n",
    "        store_attr('qdata, qzero, qscale, zeros_zero, zeros_scale, scales_zero, scales_scale', self)\n",
    "        self.data_shape,self.zero_shape,self.scale_shape = data.shape, zero.shape, scale.shape\n",
    "\n",
    "    def dequant(self):\n",
    "        zero  = self._dequant(self.qzero,  self.zeros_zero,  self.zeros_scale,  self.zero_shape,  self.group_size_zero,  self.packed)\n",
    "        scale = self._dequant(self.qscale, self.scales_zero, self.scales_scale, self.scale_shape, self.group_size_scale, self.packed)\n",
    "        return  self._dequant(self.qdata,  zero,             scale,             self.data_shape,  self.group_size,       self.packed).to(self.compute_dtype)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.dequant()@x + self.b(self.a(x))\n",
    "        col_norms =  (self.dequant() + self.b.weight @ self.a.weight).norm(p=2, dim=1).detach()\n",
    "        x /= col_norms\n",
    "        x *= self.m * self.alpha\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d6153fbb-e480-45a5-bd43-62064b575b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.03, -0.16, -0.25,  0.38],\n",
       "        [ 0.13,  0.37, -0.12, -0.47],\n",
       "        [-0.07, -0.41,  0.50,  0.15],\n",
       "        [ 0.19, -0.39, -0.34, -0.15],\n",
       "        [-0.49,  0.48,  0.10, -0.05]], dtype=torch.float16)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_linear = nn.Linear(4,5, bias=False, dtype=fp16) # ignore bias for now\n",
    "base_linear.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "44d83c4d-0b9d-49a8-a13e-b47b13db9a20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.06, 0.13, 1.72, 1.35], dtype=torch.float16)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tst = torch.randn(4, dtype=fp16); x_tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d5d69580-0c9a-410e-9d7a-257a0dcec829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.04, -0.65,  0.93, -0.64, -0.35], dtype=torch.float16, grad_fn=<SqueezeBackward4>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tst = base_linear(x_tst); y_tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8667db-744a-4f71-a247-18ad7d406c10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f0ee2a8c-6952-4941-842a-4374b6bc6f16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuantedDoraModule(\n",
       "  (a): Linear(in_features=4, out_features=2, bias=False)\n",
       "  (b): Linear(in_features=2, out_features=5, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qdora = QuantedDoraModule(base_linear, bits=3, group_size=5, group_size_zero=4, group_size_scale=4, rank=2, alpha=1, compute_dtype=fp16); qdora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ca43823f-f789-44e4-b01f-d905c0b9e032",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_qdora = qdora(x_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b0d8899f-8246-4cdb-adf8-8d32ad10d19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quanted result (with packing): tensor([ 0.11, -0.70,  0.88, -0.57, -0.37], dtype=torch.float16, grad_fn=<MulBackward0>)\n",
      "exact   result               : tensor([ 0.04, -0.65,  0.93, -0.64, -0.35], dtype=torch.float16, grad_fn=<SqueezeBackward4>)\n"
     ]
    }
   ],
   "source": [
    "print(f'quanted result (with packing): {y_qdora}')\n",
    "print(f'exact   result               : {y_tst}')\n",
    "assert_somehow_close(y_qdora, y_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98828f0-d6f9-4ea6-90fb-0c0ed9156a88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "050c8c0a-5341-4c30-8086-966bdcd9a527",
   "metadata": {},
   "source": [
    "Let's call backwards on the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "afd43544-9e0e-4e1f-9a99-8859d3e4ee0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert {n for n,p in qdora.named_parameters()} == {'m','a.weight','b.weight'} # assert only the dora part is trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df823415-ba36-4669-8ddc-a8bb74bd0b74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "89483648-91a2-422b-9cef-bb4138b04055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.65, dtype=torch.float16, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = y_qdora.sum() # abitrary operation to make y_qdora a scalar\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "97aebc50-a137-4ad0-9f54-4678123c8a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "631658a8-80e3-4cef-a480-348d2a4cddf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss shapes:\n",
      "Shape of grad of m        is [5]    ; shape of  m        is [5]\n",
      "Shape of grad of a.weight is [2, 4] ; shape of  a.weight is [2, 4]\n",
      "Shape of grad of b.weight is [5, 2] ; shape of  b.weight is [5, 2]\n"
     ]
    }
   ],
   "source": [
    "print('Loss shapes:')\n",
    "for n,p in qdora.named_parameters():\n",
    "    print(f'Shape of grad of {n:<8} is {str(list(p.grad.shape)):<7}; shape of  {n:<8} is {list(p.shape)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "284b3cee-6cdb-4c82-b26b-38899ee8ab22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- m.grad:\n",
      "tensor([ 0.22, -1.12,  1.32, -1.00, -0.54], dtype=torch.float16)\n",
      "--- a.weight.grad:\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], dtype=torch.float16)\n",
      "--- b.weight.grad:\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]], dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "for n,p in qdora.named_parameters():\n",
    "    print(f'--- {n}.grad:\\n{p.grad}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e312c2c-c120-43f6-9682-5a82a73c545f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc5595d-f240-4adf-9594-7b3ac2a33bfd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
