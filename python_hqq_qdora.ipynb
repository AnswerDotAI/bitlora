{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "035941a3-fd58-48e6-a43a-fea00f672b41",
   "metadata": {},
   "source": [
    "In this nb, I want to\n",
    "1. create the Python context to run a hqq-qdora forward and backward, and\n",
    "2. write simple kernels for those, and\n",
    "3. call them from Python context\n",
    "\n",
    "Note: I'm not using inheritance to produce cleaner code in this nb. The goal is to have a single class with all the functionality in one place. This will make it easier later to write kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "225deadd-a13a-4146-bfb2-a6d91bf2b610",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import tensor, cat, int32\n",
    "from torch import float16 as fp16\n",
    "from math import ceil\n",
    "\n",
    "torch.set_printoptions(linewidth=200, precision=2, sci_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6f82477-707c-4358-8a2d-acf9202d4daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assert_close(a,b): assert torch.isclose(a,b,atol=1e-2).all()\n",
    "def assert_somehow_close(a,b): assert torch.isclose(a,b,atol=0.07).all() # allow error of 0.07 due to quanting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b020e820-d9af-474d-a124-13b6a86c8a71",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2a6675-7930-48f2-9173-c3f234e34888",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3aa32450-d5ff-49dd-ab69-cac1ec1c02ac",
   "metadata": {},
   "source": [
    "## Implement qdora in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7fc50e8-0aec-49d0-be67-6f4611a9b16b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.45,  0.12, -0.46,  0.42],\n",
       "        [ 0.01,  0.23, -0.23, -0.09],\n",
       "        [-0.41,  0.39,  0.25, -0.33],\n",
       "        [-0.24,  0.09, -0.34,  0.23],\n",
       "        [-0.46,  0.40,  0.15,  0.41]], dtype=torch.float16)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_linear = nn.Linear(4,5, bias=False, dtype=fp16) # ignore bias for now\n",
    "base_linear.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ecc1888-9a4a-40e9-bb4f-42d95657d83f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.47,  0.87, -1.61,  1.72], dtype=torch.float16)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst_x = torch.randn(4, dtype=fp16); tst_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4caa8d6-6680-4745-81ab-95463cfec1f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.79,  0.41, -0.44,  1.13,  1.03], dtype=torch.float16, grad_fn=<SqueezeBackward4>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst_result = base_linear(tst_x); tst_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6668bf-d651-4250-956d-4b52649cbdea",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Dummy Quanted Module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b30f5d-ee85-49e9-b801-cb6c12a81dd6",
   "metadata": {},
   "source": [
    "The quanted module looks like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "683b4786-06b9-46ad-b143-225e02f045c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantedModule(nn.Module):\n",
    "    def __init__(self, linear, group_size):\n",
    "        super().__init__()\n",
    "        self.data, self.zero_points, self.scales = self.quant(linear, group_size)\n",
    "        self.in_features,self.out_features = linear.in_features,linear.out_features\n",
    "\n",
    "    @staticmethod\n",
    "    def quant(linear, group_size):\n",
    "        # # Only done once, so okay to use unoptimized off-the-shelf code\n",
    "        #\n",
    "        # get model weights\n",
    "        # quantize model weights; which gives 1. quantized data and 2. optional metadata (for hqq: zero point, scale per group)\n",
    "        # store quantized data and metadata in new nn.Module\n",
    "        # return it\n",
    "\n",
    "        return linear.weight.data, 0., 1. # for now, let's not quant\n",
    "    \n",
    "    def dequant(self):\n",
    "        # # Done many times, so should be part of an optimized kernel\n",
    "        return (self.data-self.zero_points)*self.scales # todo: dequant per group\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.dequant()@x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1162d15f-aa26-49eb-8000-17fd20379870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuantedModule()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quanted_lin = QuantedModule(base_linear, group_size=8)\n",
    "quanted_lin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "148363ac-1c46-4efc-9693-31d363436a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.79,  0.42, -0.44,  1.13,  1.03], dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "print(quanted_lin(tst_x))\n",
    "assert_close(quanted_lin(tst_x), tst_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c37092-83a2-4443-96c5-436b68270d6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "74394332-7658-4d23-85ee-078aea735364",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Dora Module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17d0e75-38b3-42f4-96f9-8efb17267d2e",
   "metadata": {},
   "source": [
    "A dora module looks like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6fa454e-1e95-4c0e-8f86-3240dee64cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check column-wise norm works as expected\n",
    "t =  torch.arange(0,30, dtype=torch.float16).reshape(5,-1)\n",
    "t_norm = t.norm(p=2,dim=1,keepdim=True)\n",
    "t_magnitudes = ((t/t_norm)**2).sum(axis=1)\n",
    "assert_close(t_magnitudes, torch.ones_like(t_magnitudes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27300699-0312-4579-bf72-9d161f137dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoraModule(nn.Module):\n",
    "    def __init__(self, linear, rank, alpha):\n",
    "        super().__init__()\n",
    "        self.base = linear\n",
    "        self.a = nn.Linear(linear.in_features, rank, bias=False, dtype=fp16)\n",
    "        self.b = nn.Linear(rank, linear.out_features, bias=False, dtype=fp16)\n",
    "        self.alpha = alpha\n",
    "        self.m = nn.Parameter(linear.weight.norm(p=2, dim=1))\n",
    "        # init a & b to 0 -- a should be inited differently, but for sake of simplicity, set it to 0 as well\n",
    "        self.a.weight.data.zero_()\n",
    "        self.b.weight.data.zero_()\n",
    "        # Make base non-trainable\n",
    "        for param in self.base.parameters(): param.requires_grad = False\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.base(x) + self.b(self.a(x))\n",
    "        col_norms =  (self.base.weight + self.b.weight @ self.a.weight).norm(p=2, dim=1).detach()\n",
    "        x /= col_norms\n",
    "        x *= self.m * self.alpha\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48e20fe4-cc77-4783-a011-04bb7d8b6d7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DoraModule(\n",
       "  (base): Linear(in_features=4, out_features=5, bias=False)\n",
       "  (a): Linear(in_features=4, out_features=2, bias=False)\n",
       "  (b): Linear(in_features=2, out_features=5, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dora = DoraModule(base_linear, rank=2, alpha=1); dora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f3054d7-4248-43fc-ab1c-8d880f685dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.79,  0.41, -0.44,  1.13,  1.03], dtype=torch.float16, grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(dora(tst_x))\n",
    "assert_close(dora(tst_x), tst_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30751da-f6e0-46ce-9e54-e63cfcb01c2a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Dummy QuantedDoraModule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb58727-9cae-4d4d-b5f2-c1027ff0d798",
   "metadata": {},
   "source": [
    "Here's the QuantedDoraModule:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b4e4b6b-3bc2-4f2c-bf97-719f6fd719b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combination of QuantedModule and DoraModule\n",
    "class QuantedDoraModule(nn.Module):    \n",
    "    def __init__(self, linear, group_size, rank, alpha):\n",
    "        super().__init__()\n",
    "        self.base = {k:v for k,v in zip(('data', 'zero_points', 'scales'), self.quant(linear, group_size))}        \n",
    "        self.a = nn.Linear(linear.in_features, rank, bias=False, dtype=fp16)\n",
    "        self.b = nn.Linear(rank, linear.out_features, bias=False, dtype=fp16)\n",
    "        self.alpha = alpha\n",
    "        self.m = nn.Parameter(linear.weight.norm(p=2, dim=1))\n",
    "        # init a & b to 0 -- a should be inited differently, but for sake of simplicity, set it to 0 as well\n",
    "        self.a.weight.data.zero_()\n",
    "        self.b.weight.data.zero_()\n",
    "    \n",
    "    @staticmethod\n",
    "    def quant(linear, group_size):\n",
    "        # # Only done once, so okay to use unoptimized off-the-shelf code\n",
    "        #\n",
    "        # get model weights\n",
    "        # quantize model weights; which gives 1. quantized data and 2. optional metadata (for hqq: zero point, scale per group)\n",
    "        # store quantized data and metadata in new nn.Module\n",
    "        # return it\n",
    "\n",
    "        return linear.weight.data, 0., 1. # for now, let's not quant\n",
    "    \n",
    "    def dequant(self):\n",
    "        # # Done many times, so should be part of an optimized kernel\n",
    "        return (self.base['data']-self.base['zero_points'])*self.base['scales'] # todo: dequant per group\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.dequant()@x + self.b(self.a(x))\n",
    "        col_norms =  (self.dequant() + self.b.weight @ self.a.weight).norm(p=2, dim=1).detach()\n",
    "        x /= col_norms\n",
    "        x *= self.m * self.alpha\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d519e34e-c921-4c38-a610-7dd2b80b2d00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuantedDoraModule(\n",
       "  (a): Linear(in_features=4, out_features=2, bias=False)\n",
       "  (b): Linear(in_features=2, out_features=5, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qdora = QuantedDoraModule(base_linear, group_size=8, rank=2, alpha=1); qdora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "877a2658-01ab-438d-b156-1b40ddd757df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.79,  0.42, -0.44,  1.13,  1.03], dtype=torch.float16, grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(qdora(tst_x))\n",
    "assert_close(qdora(tst_x), tst_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69372b78-46ad-4c2b-8d89-30a7f40e6a5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05411701-1408-4b11-b40c-51157ffede01",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### With actual 3-bit quanting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fc3b3c-9074-4852-905a-79b2e4ec5d7c",
   "metadata": {},
   "source": [
    "**Now let's actually quant.** We'll do symetric grouped quanting, as hqq does (todo: verify). Let's use 3bits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceee08e9-18e2-4ffb-a4ee-e8080ffdab79",
   "metadata": {},
   "source": [
    "Let's first do it by hand, for `group_size = 5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3f05cf8-081e-4d90-b268-0b9bf98df8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bits = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ebb8d5c7-238e-4d89-a616-b7d84ab6b677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.61, -0.52,  0.34,  0.17, -0.91, -0.62, -0.32, -0.69,  0.76,  0.81],\n",
       "        [-0.62,  0.20, -0.22, -0.32,  1.87, -0.95,  1.05, -1.55, -1.51,  0.34]], dtype=torch.float16)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.randn((2,10), dtype=torch.float16); data\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f89e5dc-15d3-4b18-957c-97f521ce11fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.61, -0.52,  0.34,  0.17, -0.91], dtype=torch.float16)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_group = data.flatten()[:5]; data_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e8bbafd-441e-4c27-8f6d-c3348992b674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-1.61, dtype=torch.float16), tensor(0.34, dtype=torch.float16))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_,max_ = data_group.min(), data_group.max(); min_,max_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "714c576f-b148-4390-a6a4-c3f72a5184c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.00, 3.91, 7.00, 6.38, 2.51], dtype=torch.float16)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_group_normed = (data_group-min_)/(max_-min_) * (2**bits-1); data_group_normed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63cb6fd0-67b9-48fa-85b8-82719aea8cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 4., 7., 6., 3.], dtype=torch.float16)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_group_normed.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "177777d7-7ab1-4b2b-9191-16678eb0aa01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 4., 7., 6., 3.], dtype=torch.float16)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def quantize_group(group, bits=bits):\n",
    "    group -= group.min() # start at 0\n",
    "    group /= group.max() # scale to [0,1]\n",
    "    return (group * (2**bits-1)).round() # scale to [0, 2**bits-1]\n",
    "\n",
    "quantize_group(data.flatten()[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7450aa8-1c19-4d67-9a02-f49169cb7335",
   "metadata": {},
   "source": [
    "This can be done group-wise by reshaping into shape `(-1, group_size)` first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "026a126e-0534-43e8-906e-b1761b020b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.arange(0,30, dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1c979a6e-99cb-4ffc-9a58-dd17b25ed9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quant(data, group_size, bits):\n",
    "    shape = data.shape\n",
    "    data = data.reshape(-1,group_size)\n",
    "\n",
    "    min_, max_ = data.min(axis=-1, keepdim=True).values, data.max(axis=-1, keepdim=True).values\n",
    "\n",
    "    zero = min_\n",
    "    scale = (max_-min_) / (2**bits-1) \n",
    "\n",
    "    # note: can't use shorthand ops like -= as they modify tensor in-place\n",
    "    data = data - zero # start at 0\n",
    "    data = data / scale # scale to [0, 2**bits-1]\n",
    "    data = data.round()\n",
    "\n",
    "    return data.reshape(shape), scale, zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0d9a04f9-f6d1-4959-8027-fb1d9e6c150c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 2., 4., 5., 7.],\n",
      "        [0., 2., 4., 5., 7.],\n",
      "        [0., 2., 4., 5., 7.],\n",
      "        [0., 2., 4., 5., 7.],\n",
      "        [0., 2., 4., 5., 7.],\n",
      "        [0., 2., 4., 5., 7.]], dtype=torch.float16)\n",
      "tensor([0.57, 0.57, 0.57, 0.57, 0.57, 0.57], dtype=torch.float16)\n",
      "tensor([ 0.,  5., 10., 15., 20., 25.], dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "qdata, qscale, qzero = quant(data, group_size=5, bits=3)\n",
    "\n",
    "# reshape/flatten for better visibility\n",
    "print(qdata.reshape(-1,5))\n",
    "print(qscale.flatten())\n",
    "print(qzero.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fd7a33-fef9-4802-9cd5-ac017a3e3859",
   "metadata": {},
   "source": [
    "As expected:\n",
    "- the 1st element in each group is now 0, as it was the min in that group\n",
    "- the scales are identical\n",
    "- the zeros are 5*i for i = 0,...,5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7df1cc43-052d-4c66-9a87-5d5d045250fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dequant(qdata, scale, zero, group_size):\n",
    "    shape = qdata.shape\n",
    "    data = qdata.reshape(-1,group_size)\n",
    "    data = data*scale + zero\n",
    "    return data.reshape(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1af0c35a-41fe-45d7-b64d-79d93a420435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.00,  1.14,  2.29,  2.86,  4.00],\n",
       "        [ 5.00,  6.14,  7.29,  7.86,  9.00],\n",
       "        [10.00, 11.14, 12.28, 12.86, 14.00],\n",
       "        [15.00, 16.14, 17.28, 17.86, 19.00],\n",
       "        [20.00, 21.14, 22.28, 22.86, 24.00],\n",
       "        [25.00, 26.14, 27.28, 27.86, 29.00]], dtype=torch.float16)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dequant(qdata,qscale,qzero, group_size=5).reshape(-1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8124db7b-5978-4761-9d18-6b799479b954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.,  3.,  4.],\n",
       "        [ 5.,  6.,  7.,  8.,  9.],\n",
       "        [10., 11., 12., 13., 14.],\n",
       "        [15., 16., 17., 18., 19.],\n",
       "        [20., 21., 22., 23., 24.],\n",
       "        [25., 26., 27., 28., 29.]], dtype=torch.float16)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.reshape(-1,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07ae5bd-efd6-4c04-a3f9-dcd154fb09f5",
   "metadata": {},
   "source": [
    "Looks good! Let's implement this into the new version of `QuantedDoraModule`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dc20f3ed-b42e-4d6e-8dda-4b1414dfd5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantedDoraModule(nn.Module):\n",
    "    def __init__(self, linear, bits, group_size, rank, alpha):\n",
    "        super().__init__()\n",
    "        # for quanting\n",
    "        self.bits,self.group_size, = bits,group_size\n",
    "        self.quant(linear)\n",
    "        # for dora\n",
    "        self.a = nn.Linear(linear.in_features, rank, bias=False, dtype=fp16)\n",
    "        self.b = nn.Linear(rank, linear.out_features, bias=False, dtype=fp16)\n",
    "        self.alpha = alpha\n",
    "        self.m = nn.Parameter(linear.weight.norm(p=2, dim=1))\n",
    "        # init a & b to 0 -- a should be inited differently, but for sake of simplicity, set it to 0 as well\n",
    "        self.a.weight.data.zero_()\n",
    "        self.b.weight.data.zero_()\n",
    "\n",
    "    def quant(self, linear):\n",
    "        data = linear.weight.data\n",
    "        shape = data.shape\n",
    "\n",
    "        # repeat last element, to have a multiple of group_size elements\n",
    "        # note: element to pad with mustn't change any attribute that's use for quanting (eg min & max in a group)\n",
    "        n_pad = data.numel()%self.group_size\n",
    "        data = F.pad(data, (0,n_pad), 'constant', data.flatten()[-1])\n",
    "        assert data.numel()%self.group_size==0\n",
    "\n",
    "        data = data.reshape(-1,self.group_size)\n",
    "        \n",
    "        min_, max_ = data.min(axis=-1, keepdim=True).values, data.max(axis=-1, keepdim=True).values\n",
    "        \n",
    "        self.zero = min_\n",
    "        self.scale = (max_-min_) / (2**self.bits-1) \n",
    "        \n",
    "        # note: can't use shorthand ops like -= as they modify tensor in-place\n",
    "        data = data - self.zero # start at 0\n",
    "        data = data / self.scale # scale to [0, 2**bits-1]\n",
    "        data = data.round()\n",
    "        \n",
    "        self.qdata = data.reshape(shape)\n",
    "\n",
    "    def dequant(self):\n",
    "        # # Done many times, so should be part of an optimized kernel\n",
    "        shape = self.qdata.shape\n",
    "        data = self.qdata.reshape(-1,self.group_size)\n",
    "        data = data*self.scale + self.zero\n",
    "        return data.reshape(shape)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.dequant()@x + self.b(self.a(x))\n",
    "        col_norms =  (self.dequant() + self.b.weight @ self.a.weight).norm(p=2, dim=1).detach()\n",
    "        x /= col_norms\n",
    "        x *= self.m * self.alpha\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fcc29a49-4e00-41aa-90d4-733571e8784d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuantedDoraModule(\n",
       "  (a): Linear(in_features=4, out_features=2, bias=False)\n",
       "  (b): Linear(in_features=2, out_features=5, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qdora = QuantedDoraModule(base_linear, bits=3, group_size=5, rank=2, alpha=1); qdora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b7a9b177-dede-443f-b9cc-345ea964ee2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quanted result: tensor([ 1.80,  0.40, -0.45,  1.14,  1.00], dtype=torch.float16, grad_fn=<MulBackward0>)\n",
      "exact   result: tensor([ 1.79,  0.41, -0.44,  1.13,  1.03], dtype=torch.float16, grad_fn=<SqueezeBackward4>)\n"
     ]
    }
   ],
   "source": [
    "print(f'quanted result: {qdora(tst_x)}')\n",
    "print(f'exact   result: {tst_result}')\n",
    "assert_somehow_close(qdora(tst_x), tst_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb91b87-a610-4e08-b568-b29e1a26de56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "64c86c62-bee7-4d9a-b103-9572071eb044",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_result_3bit_quanting = qdora(tst_x) # save to compare against later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cb97ca-1ef2-49ed-9634-172713fca7ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4298558d-ea19-4731-9efe-7bb24640c133",
   "metadata": {},
   "source": [
    "### With Packing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a1f2aa-a0fe-4a02-a7c5-b5f03b1cbcee",
   "metadata": {},
   "source": [
    "**Now, let's store the quanted values more efficiently**, by storing 10 quanted 3bit-values together in a uint32 ('packing')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3b918f12-a42b-4ceb-be66-99e0af17cb54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We want to pack this data:\n",
      "tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24.], dtype=torch.float16)\n",
      "which has 25 items into 3 uint32s.\n"
     ]
    }
   ],
   "source": [
    "data = torch.arange(25, dtype=fp16)\n",
    "n_data = data.numel()\n",
    "n_packs = tensor(n_data/10).ceil().to(dtype=int)\n",
    "\n",
    "print(f'We want to pack this data:\\n{data}\\nwhich has {n_data} items into {n_packs} uint32s.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "90ae67ec-5397-4c95-8b81-a3e7b2ae05fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 2., 4., 5., 7., 0., 2., 4., 5., 7., 0., 2., 4., 5., 7., 0., 2., 4., 5., 7., 0., 2., 4., 5., 7.], dtype=torch.float16),\n",
       " tensor([[0.57],\n",
       "         [0.57],\n",
       "         [0.57],\n",
       "         [0.57],\n",
       "         [0.57]], dtype=torch.float16),\n",
       " tensor([[ 0.],\n",
       "         [ 5.],\n",
       "         [10.],\n",
       "         [15.],\n",
       "         [20.]], dtype=torch.float16))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qdata, scales, zeros = quant(data, group_size=5, bits=3)\n",
    "qdata, scales, zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7ebb0659-4c71-4069-9491-d6de8c1dbbb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 2., 4., 5., 7., 0., 2., 4., 5., 7.], dtype=torch.float16)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_pack_0 = qdata[:10]; to_pack_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d6b98413-0fb4-4002-a4e4-fa93900ec621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43484463"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pack\n",
    "pack_0 = 0\n",
    "for x in to_pack_0: pack_0 = (pack_0 << 3) | int(x) # shift right 3 bits, then set last 3 bits to x\n",
    "pack_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "908b3f5b-c21a-4565-81be-9b899e16dfb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# unpack\n",
    "binary = [int(b) for b in format(pack_0, '032b')]\n",
    "print(binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5049d759-5255-4e21-afbd-4883ca1ed099",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_to_dec(b3,b2,b1): return 4*b3 + 2*b2 + b1\n",
    "assert bin_to_dec(1,1,1)==7\n",
    "assert bin_to_dec(1,0,1)==5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0dadf0c7-d79e-454b-8795-882e908b9255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 4, 5, 7, 0, 2, 4, 5, 7]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\n",
    "    bin_to_dec(*binary[2+3*i:2+3*(i+1)]) # first 2 bits are not used; then every 3 bits represent one value\n",
    "    for i in range(10)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa3a067-fce4-4ad6-b7af-fff13a8a77e5",
   "metadata": {},
   "source": [
    "Yup, these are the values we originally packed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d08c82-e8e1-440b-a0b3-d08086642ba9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dae96efa-626f-4f08-a3af-a16330792880",
   "metadata": {},
   "source": [
    "The unpacking method uses an intermediate string representation. That is slow. Let's unpack on the raw binary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76031415-86cf-4ff2-9717-34bd6544dc05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cc0cebba-44cd-431e-944b-833a3d81fa4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 4, 5, 7, 0, 2, 4, 5, 7]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\n",
    "    (pack_0 >> (3*i)) & 0b111 # righ-shift 3*i times, so last 3 bits are those we want; then only select those via 0b111\n",
    "    for i in reversed(range(10))\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c2035f-3eaa-4d30-8914-14064b29c8a7",
   "metadata": {},
   "source": [
    "Yes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b96eb3-e379-441d-8733-77cf75c8870f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6dd01f5a-cd7a-4dad-8fe5-e7064d256e07",
   "metadata": {},
   "source": [
    "Let's createa a packing and unpacking function now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "55e2d597-8759-40b7-888d-643e8c7caa3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "118b10d4-6963-4ccd-920a-2fcc0caf9401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pack 10 3bit values into a 32bit val\n",
    "def pack(vals):\n",
    "    for v in vals: assert 0<=v<=7 and v//1==v, f'Value {v} can\\'t be represented by 3 bits or is not an integer'\n",
    "    \n",
    "    n_packs = math.ceil(len(vals)/10)\n",
    "\n",
    "    # pad with 0, to have a multiple of pack_size elements\n",
    "    n_pad = n_packs*10 - len(vals)\n",
    "    vals = F.pad(vals, (0,n_pad), 'constant', 0)\n",
    "    assert len(vals)==n_packs*10\n",
    "\n",
    "    packed = torch.zeros(n_packs, dtype=torch.int32)\n",
    "    for i in range(n_packs):\n",
    "        # pack the 10 vals from 10*i to 10*(i+1) into packed[i]\n",
    "        for x in vals[10*i:10*(i+1)]: packed[i] = (packed[i] << 3) | x # shift right 3 bits, then set last 3 bits to x\n",
    "    return packed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e3df5d2f-ac0d-42f2-8416-e20bd46487fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 21913025, 328466432], dtype=torch.int32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst_values = tensor([0,1,2,3,4,5,6,7,0,1,2,3,4,5])\n",
    "\n",
    "packed = pack(tst_values); packed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c95872c0-3950-4f74-994b-a41eb0740f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpack a 32bit value into 10 3bit vals\n",
    "def unpack(packed):\n",
    "    def bin_to_dec(b3,b2,b1): return 4*b3 + 2*b2 + b1\n",
    "    for v in packed: isinstance(v, int), f'Value {v} is not an integer'\n",
    "    unpacked = []\n",
    "    for pack in packed:\n",
    "        for i in reversed(range(10)):\n",
    "            unpacked.append((pack >> (3*i)) & 0b111) # righ-shift 3*i times, so last 3 bits are those we want; then only select those via 0b111            \n",
    "    return tensor(unpacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "127f7b47-45de-4a67-8437-a5d55d3d9b24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 0, 0, 0, 0, 0, 0], dtype=torch.int32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unpack(packed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d20133ae-498d-408e-9c3a-703512cbc879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 0, 0, 0, 0, 0, 0], dtype=torch.int32)\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "print(unpack(packed))\n",
    "print(tst_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fce984-4fdb-4345-a09c-febff5620270",
   "metadata": {},
   "source": [
    "Look's good!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aed621c-4b19-4c64-bd01-4afac8433620",
   "metadata": {},
   "source": [
    "Time to put this into `QuantedDoraModule`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6c9d7e70-f910-4f1e-a241-5577c19a9824",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantedDoraModule(nn.Module):\n",
    "    def __init__(self, linear, bits, group_size, rank, alpha):\n",
    "        super().__init__()\n",
    "        # for quanting\n",
    "        assert base_linear.weight.numel() % group_size ==0, f'group_size {group_size} can\\'t cleanly split weight of base layer ({base_linear.weight.numel()} items)'\n",
    "        self.bits,self.group_size, = bits,group_size\n",
    "        self.quant(linear)\n",
    "        # for dora\n",
    "        self.a = nn.Linear(linear.in_features, rank, bias=False, dtype=fp16)\n",
    "        self.b = nn.Linear(rank, linear.out_features, bias=False, dtype=fp16)\n",
    "        self.alpha = alpha\n",
    "        self.m = nn.Parameter(linear.weight.norm(p=2, dim=1))\n",
    "        # init a & b to 0 -- a should be inited differently, but for sake of simplicity, set it to 0 as well\n",
    "        self.a.weight.data.zero_()\n",
    "        self.b.weight.data.zero_()\n",
    "\n",
    "    def quant(self, linear):\n",
    "        data = linear.weight.data\n",
    "        self.shape = data.shape\n",
    "\n",
    "        # repeat last element, to have a multiple of group_size elements\n",
    "        # note: element to pad with mustn't change any attribute that's use for quanting (eg min & max in a group)\n",
    "        n_pad = data.numel()%self.group_size\n",
    "        data = F.pad(data, (0,n_pad), 'constant', data.flatten()[-1])\n",
    "        assert data.numel()%self.group_size==0\n",
    "\n",
    "        data = data.reshape(-1,self.group_size)\n",
    "        \n",
    "        min_, max_ = data.min(axis=-1, keepdim=True).values, data.max(axis=-1, keepdim=True).values\n",
    "        \n",
    "        self.zero = min_\n",
    "        self.scale = (max_-min_) / (2**self.bits-1) \n",
    "        \n",
    "        # note: can't use shorthand ops like -= as they modify tensor in-place\n",
    "        data = data - self.zero # start at 0\n",
    "        data = data / self.scale # scale to [0, 2**bits-1]\n",
    "        data = data.round().to(int)\n",
    "\n",
    "        # packed quantized data\n",
    "        self.pqdata = self.pack(data.flatten())\n",
    "\n",
    "    # pack 10 3bit values into a 32bit val\n",
    "    @staticmethod\n",
    "    def pack(vals):\n",
    "        for v in vals: assert 0<=v<=7 and v//1==v, f'Value {v} can\\'t be represented by 3 bits or is not an integer'\n",
    "        \n",
    "        n_packs = math.ceil(len(vals)/10)\n",
    "    \n",
    "        # pad with 0, to have a multiple of pack_size elements\n",
    "        n_pad = n_packs*10 - len(vals)\n",
    "        vals = F.pad(vals, (0,n_pad), 'constant', 0)\n",
    "        assert len(vals)==n_packs*10\n",
    "    \n",
    "        packed = torch.zeros(n_packs, dtype=int32)\n",
    "        for i in range(n_packs):\n",
    "            # pack the 10 vals from 10*i to 10*(i+1) into packed[i]\n",
    "            for x in vals[10*i:10*(i+1)]: packed[i] = (packed[i] << 3) | x # shift right 3 bits, then set last 3 bits to x\n",
    "        return packed\n",
    "\n",
    "    def dequant(self):\n",
    "        data = self.unpack(self.pqdata)[:self.shape.numel()] # unpack & remove padding that was added during packing\n",
    "        data = data.reshape(-1,self.group_size)\n",
    "        data = data*self.scale + self.zero\n",
    "        return data.reshape(self.shape)\n",
    "    \n",
    "    # unpack a 32bit value into 10 3bit vals\n",
    "    @staticmethod\n",
    "    def unpack(packed):\n",
    "        def bin_to_dec(b3,b2,b1): return 4*b3 + 2*b2 + b1\n",
    "        for v in packed: isinstance(v, int), f'Value {v} is not an integer'\n",
    "        unpacked = []\n",
    "        for pack in packed:\n",
    "            for i in reversed(range(10)):\n",
    "                unpacked.append((pack >> (3*i)) & 0b111) # righ-shift 3*i times, so last 3 bits are those we want; then only select those via 0b111            \n",
    "        return tensor(unpacked)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.dequant()@x + self.b(self.a(x))\n",
    "        col_norms =  (self.dequant() + self.b.weight @ self.a.weight).norm(p=2, dim=1).detach()\n",
    "        x /= col_norms\n",
    "        x *= self.m * self.alpha\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f0ee2a8c-6952-4941-842a-4374b6bc6f16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuantedDoraModule(\n",
       "  (a): Linear(in_features=4, out_features=2, bias=False)\n",
       "  (b): Linear(in_features=2, out_features=5, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qdora = QuantedDoraModule(base_linear, bits=3, group_size=5, rank=2, alpha=1); qdora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b0d8899f-8246-4cdb-adf8-8d32ad10d19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quanted result (with packing): tensor([ 1.80,  0.40, -0.45,  1.14,  1.00], dtype=torch.float16, grad_fn=<MulBackward0>)\n",
      "quanted result (w/o  packing): tensor([ 1.80,  0.40, -0.45,  1.14,  1.00], dtype=torch.float16, grad_fn=<MulBackward0>)\n",
      "exact   result               : tensor([ 1.79,  0.41, -0.44,  1.13,  1.03], dtype=torch.float16, grad_fn=<SqueezeBackward4>)\n"
     ]
    }
   ],
   "source": [
    "print(f'quanted result (with packing): {qdora(tst_x)}')\n",
    "print(f'quanted result (w/o  packing): {tst_result_3bit_quanting}')\n",
    "print(f'exact   result               : {tst_result}')\n",
    "assert_somehow_close(qdora(tst_x), tst_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b84ad3-5552-47bd-a01a-7ce95a99b5c2",
   "metadata": {},
   "source": [
    "Packing doesn't change the result -- as it should! Very good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98828f0-d6f9-4ea6-90fb-0c0ed9156a88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae8d1bb-74de-46eb-a72a-3ec24dabf099",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f8b800-dd0e-4b16-b36f-548fb85392f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27253df5-dc04-4970-b41d-5ed52abd41b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "050c8c0a-5341-4c30-8086-966bdcd9a527",
   "metadata": {},
   "source": [
    "Let's call backwards on the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "afd43544-9e0e-4e1f-9a99-8859d3e4ee0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert only the dora part is trainable\n",
    "assert {n for n,p in qdora.named_parameters()} == {'m','a.weight','b.weight'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df823415-ba36-4669-8ddc-a8bb74bd0b74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f4bb052d-0cc4-4ab4-b701-19eb0c989e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is    : tensor([ 1.80,  0.40, -0.45,  1.14,  1.00], dtype=torch.float16, grad_fn=<MulBackward0>)\n",
      "Result should: tensor([ 3.58,  0.83, -0.88,  2.26,  2.05], dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "y_is = (tst_result*2).detach()\n",
    "y_pred = qdora(tst_x)\n",
    "\n",
    "print(f'Result is    : {y_pred}')\n",
    "print(f'Result should: {y_is}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "859392e9-9167-42f2-8a5f-33f055f5d34e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.42, dtype=torch.float16, grad_fn=<SqrtBackward0>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = (y_pred-y_is).square().sum().sqrt()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "97aebc50-a137-4ad0-9f54-4678123c8a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "631658a8-80e3-4cef-a480-348d2a4cddf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of loss of m        is [5]    ; shape of  m        is [5]\n",
      "Shape of loss of a.weight is [2, 4] ; shape of  a.weight is [2, 4]\n",
      "Shape of loss of b.weight is [5, 2] ; shape of  b.weight is [5, 2]\n"
     ]
    }
   ],
   "source": [
    "for n,p in qdora.named_parameters():\n",
    "    print(f'Shape of loss of {n:<8} is {str(list(p.grad.shape)):<7}; shape of  {n:<8} is {list(p.shape)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284b3cee-6cdb-4c82-b26b-38899ee8ab22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e830b2a9-852c-4eb2-ba14-f9caad2d5d9b",
   "metadata": {},
   "source": [
    "**Q:** How can we tell PyTorch to use a custom kernel for a sequence of operations? Especially for backwards, which is an op we don't define ourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e312c2c-c120-43f6-9682-5a82a73c545f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc5595d-f240-4adf-9594-7b3ac2a33bfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "511711c5-71b1-46ac-ba8d-7c405b7d4895",
   "metadata": {},
   "source": [
    "## Kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862a560d-00b1-4424-83e2-c6fc76287d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TRITON_INTERPRET'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f851cc51-8cb9-4b98-9dbc-dd68cdcbffdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85caa243-f2db-41d6-814c-1882e52b7d37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "287bc5d2-b18f-460b-b849-a0ea995e1b77",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6ee0c0-f8b6-4a8d-8693-1a732e5fbe39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb444e9-303f-4a65-b2f5-db40ab1d05cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
