{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16b61030-dcc2-4d3a-a0a7-7ce3f228bc77",
   "metadata": {},
   "source": [
    "I've analytically derived the gradient of dora wrt `b` (lora up),`a` (lora down) and `m` (magnitude).\n",
    "\n",
    "In this nb, I verify my analytical derivative against the pytorch autograd derivative. **Edit:** They match!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76dadc31-5007-4a36-a5ea-b7dfffa87521",
   "metadata": {},
   "source": [
    "Reminder: The dora forward is `y = (w + b@a)@x * mag * alpha / col_norms`, where `@` is matmul, `*`, `/` and `+` are pointwise, and the shapes are:\n",
    "- `w ~ (m,n)`\n",
    "- `b ~ (m,r)`\n",
    "- `a ~ (r,n)`\n",
    "- `mag ~ (m)`\n",
    "- `col_norms ~ (m)`\n",
    "- `alpha ~ ()` (ie a scalar)\n",
    "- `x ~ (bs, n)` (bs = batch size)\n",
    "- `y ~ (bs, m)`\n",
    "\n",
    "Also, as in the dora paper, `col_norms` is treated as constant in the backward (even though it depends on `a` and `b`), which greatly simplifies the backward."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5883dc90-3756-4530-8ac8-4575fb979dcc",
   "metadata": {},
   "source": [
    "Note: PyTorch autograd only yields the **total derivative** of the **final loss**, **evaluated at a point**, eg for `b`:\n",
    "$$\\frac{\\partial \\text{loss}}{\\partial b} \\Big|_{x} = \\frac{\\partial \\text{loss}}{\\partial y} \\Big|_{x} \\cdot \\frac{\\partial y}{\\partial b} \\Big|_{x}$$\n",
    "What we are interested in, however, is the function $x \\mapsto \\frac{\\partial y}{\\partial b}\\Big|_{x}$ (and same for $\\frac{\\partial y}{\\partial a}$ and $\\frac{\\partial y}{\\partial m}$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7168ef-3696-4072-84fb-b83a689d3425",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import tensor, diag, isclose\n",
    "\n",
    "torch.set_printoptions(precision=2, sci_mode=False, linewidth=200)\n",
    "\n",
    "from einops import einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745fe628-8344-4cd1-8e69-8a1a69038f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_assertion = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1202d0-e59f-44bd-8aed-5c151b0a4a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self, m,r,n, alpha=10, rand_weights=True):\n",
    "        super().__init__()\n",
    "        if rand_weights:\n",
    "            # for robust testing\n",
    "            self.a = nn.Parameter(torch.randn(r, n))\n",
    "            self.b = nn.Parameter(torch.randn(m, r))\n",
    "            self.w = torch.randn(m, n)\n",
    "            self.mag = nn.Parameter(torch.randn(m))\n",
    "            self.col_norms = torch.randn(m)\n",
    "        else:\n",
    "            # for debugging\n",
    "            self.a = nn.Parameter(torch.ones(r, n) * 0.5)\n",
    "            self.b = nn.Parameter(torch.ones(m, r) * 0.3)\n",
    "            self.w = torch.ones(m, n) * 0.1    \n",
    "            self.mag = nn.Parameter(torch.ones(m) * 1.1)\n",
    "            self.col_norms = torch.ones(m) * 0.2\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x@self.w.t() + x@self.a.t()@self.b.t() # x(w+ab).t instead of (w+ab)x so it works with batched x\n",
    "        x /= self.col_norms\n",
    "        x *= self.mag * self.alpha\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6a063b-4261-4f81-880d-6b920dac8b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs,m,r,n = 2,5,3,4 # batch size, out, lora_rank, in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af9860c-116c-4c93-b845-5552026dc730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(bs,n)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0b791d-1ca2-436e-95a1-1724b75d5317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 15.84,  -5.73,  16.66, -13.06,  24.94],\n",
       "        [ 15.84,  -5.73,  16.66, -13.06,  24.94]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MyModel(m,r,n, rand_weights=True)\n",
    "y = model(x)\n",
    "print(y.shape)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb96e4de-7089-4b6d-b837-d656bdd1e8bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.73, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = y.mean()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d068bca-0db0-46e7-b3e7-d626b09b46af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad of y (shape [2, 5]):\n",
      "tensor([[0.10, 0.10, 0.10, 0.10, 0.10],\n",
      "        [0.10, 0.10, 0.10, 0.10, 0.10]])\n"
     ]
    }
   ],
   "source": [
    "y.retain_grad() # we need dloss_dy as input for our manual gradient calculation below\n",
    "loss.backward()\n",
    "print(f'grad of y (shape {list(y.grad.shape)}):\\n{y.grad}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deea3200-c3a9-4067-ac1c-7285e7db7556",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df25791-6528-400b-bcdd-cc6a8e2b2d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for notational convenience\n",
    "w,b,a = model.w.data,model.b.data,model.a.data\n",
    "mag = model.mag.data\n",
    "beta = 1 / model.col_norms.data\n",
    "alpha = model.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9855d8-c831-4ade-91d1-83346fd0fe7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(should,is_):\n",
    "    print(f'Should:\\n{should}')\n",
    "    print(f'Is    :\\n{is_}')\n",
    "    if do_assertion: assert isclose(should, is_).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1656e9ab-ae80-44a2-a9df-6311741872d2",
   "metadata": {},
   "source": [
    "**Derivate wrt mag**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2072dd13-4049-4304-a1c9-b2851e07e5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dy_dmag():\n",
    "    z = x@w.t() + x@a.t()@b.t()\n",
    "    return alpha * z[:,:,None]*diag(beta) \n",
    "assert dy_dmag().shape == (bs,m,m)\n",
    "\n",
    "def dloss_dmag(dloss_dy):\n",
    "    return einsum(dloss_dy, dy_dmag(), 'bs m, bs m m2 -> m2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d190c0c4-337e-4902-9921-1e7bd4ac9544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Should:\n",
      "tensor([11.41,  0.76, -2.34,  1.86, -6.53])\n",
      "Is    :\n",
      "tensor([11.41,  0.76, -2.34,  1.86, -6.53])\n"
     ]
    }
   ],
   "source": [
    "compare(model.mag.grad, dloss_dmag(y.grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977b33b9-fc69-43f1-bd76-05c80d400e4c",
   "metadata": {},
   "source": [
    "Yes!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b210686e-f05f-478b-bb8f-6fb00cd4c61f",
   "metadata": {},
   "source": [
    "**Derivate wrt a**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d66695d-26f3-4858-8bd9-7fd4fe68742f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dy_da():\n",
    "    return alpha * (mag * beta)[None,:,None,None] * x[:,None,None,:] * b[None,:,:,None]\n",
    "assert dy_da().shape == (bs,m,r,n)\n",
    "\n",
    "def dloss_da(dloss_dy):\n",
    "    return einsum(dloss_dy, dy_da(), 'bs m, bs m r n -> r n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808b93ca-41a4-4657-b065-3e9613f76fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Should:\n",
      "tensor([[7.93, 7.93, 7.93, 7.93],\n",
      "        [1.63, 1.63, 1.63, 1.63],\n",
      "        [1.89, 1.89, 1.89, 1.89]])\n",
      "Is    :\n",
      "tensor([[7.93, 7.93, 7.93, 7.93],\n",
      "        [1.63, 1.63, 1.63, 1.63],\n",
      "        [1.89, 1.89, 1.89, 1.89]])\n"
     ]
    }
   ],
   "source": [
    "compare(model.a.grad, dloss_da(y.grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db9d4ce-7d40-486e-978d-2a11f136b1cb",
   "metadata": {},
   "source": [
    "Yes!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31000f7-57b4-4fb6-9150-b2d2bcce6636",
   "metadata": {},
   "source": [
    "**Derivate wrt b**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1c05dd-405f-4848-9b3c-7605f94ec012",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dy_db():\n",
    "    return alpha * diag(mag*beta)[None,:,:,None] * (x@a.t())[:,None,None,:]\n",
    "assert dy_db().shape == (bs,m,m,r)\n",
    "\n",
    "def dloss_db(dloss_dy):\n",
    "    return einsum(dloss_dy, dy_db(), 'bs m, bs m m2 r -> m2 r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6472b22-9e03-49a4-aed5-71740fef0bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Should:\n",
      "tensor([[-0.01, -0.04,  0.35],\n",
      "        [-0.06, -0.18,  1.63],\n",
      "        [ 0.04,  0.12, -1.08],\n",
      "        [ 0.06,  0.18, -1.64],\n",
      "        [ 0.06,  0.20, -1.76]])\n",
      "Is    :\n",
      "tensor([[-0.01, -0.04,  0.35],\n",
      "        [-0.06, -0.18,  1.63],\n",
      "        [ 0.04,  0.12, -1.08],\n",
      "        [ 0.06,  0.18, -1.64],\n",
      "        [ 0.06,  0.20, -1.76]])\n"
     ]
    }
   ],
   "source": [
    "compare(model.b.grad, dloss_db(y.grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203d9a0b-6952-4808-8a7e-07a9a4722ed4",
   "metadata": {},
   "source": [
    "Yes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05ac710-1192-42e7-ace6-aaa574c5a471",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
