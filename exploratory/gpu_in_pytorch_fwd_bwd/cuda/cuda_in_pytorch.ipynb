{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7b6df12-ec75-4289-8e26-f56e6c858ed5",
   "metadata": {},
   "source": [
    "Let's do a tiny example of using a custom cuda kernel in a PyTorch model's forward and backward:\n",
    "\n",
    "1. Write a tiny pytorch model\n",
    "2. Write its fwd and bwd in cpp, and use it in pytorch\n",
    "3. Write its fwd and bwd in cuda, and use it in pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a776aec-fad0-4b9c-a077-2a7133ff6a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b10dc6-fc00-41c7-a632-4455d036a22c",
   "metadata": {},
   "source": [
    "## 1. Pure PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f440ba73-c703-46ec-905a-69b4f80eddcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLinear(nn.Module):\n",
    "    def __init__(self, cin, cout):\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(torch.ones(cout, cin))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.weights @ x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e42ee18-dad5-4ba1-8da9-4f3a82242365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomLinear()"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin = CustomLinear(2,3)\n",
    "lin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af90ef15-be23-4602-805e-350ba4ca06ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1.])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e4902c-5a5b-4093-8d61-9e87bce7a9c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 2., 2.], grad_fn=<MvBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = lin(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911bbd86-30a0-4388-b097-bebd0d4e0f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e6ad21-a5ef-4888-8fd3-a7a2c352532d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40325c9-244f-4a40-ad6e-747bcc3c4a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin.weights.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aec5359-6b2e-43aa-96a1-6182aa6ad474",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2450755d-3090-41e4-979b-cc6317d0a90f",
   "metadata": {},
   "source": [
    "## 2. Fwd and Bwd in Cpp:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07604a2-a78d-4ea7-bd9a-ca16c8023167",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.cpp_extension import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061db068-6fa6-4dd8-b31f-39efbd2484ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Emitting ninja build file tmp/build.ninja...\n",
      "Building extension module custom_lin_cpp...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ninja: no work to do.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading extension module custom_lin_cpp...\n"
     ]
    }
   ],
   "source": [
    "custom_lin_cpp = load(\n",
    "    name='custom_lin_cpp', \n",
    "    sources=['custom_linear.cpp'],\n",
    "    build_directory='tmp',\n",
    "    verbose=True\n",
    ")\n",
    "cpp_fwd = custom_lin_cpp.forward\n",
    "cpp_bwd = custom_lin_cpp.backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5db920a-5838-415e-8da9-dcae05b9564f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function custom_lin_cpp.PyCapsule.forward>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpp_fwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d49a932-d654-4a7a-8ef1-d5c2dbbff973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function custom_lin_cpp.PyCapsule.backward>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpp_bwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faaf49ab-652a-49fc-ae38-27bcd759bf32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 2., 2.]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpp_fwd(lin.weights, x.unsqueeze(0)) # cpp_fwd expects x to be a matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04b7eda-3996-4220-868c-98447243dcea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 1.]]),\n",
       " tensor([[3., 3.]], grad_fn=<MmBackward0>)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = torch.ones(1,3) # grad\n",
    "cpp_bwd(d, lin.weights, x.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb541b60-073a-4f54-84c7-3e50fb955eec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6876aa1e-7db4-4d6a-a16c-3c947653358c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLinearCpp(nn.Module):\n",
    "    def __init__(self, cin, cout):\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(torch.ones(cout, cin))\n",
    "\n",
    "    def forward(self, x):\n",
    "        if len(x.shape)==1: x = x.unsqueeze(0) # cpp_fwd expects x to be a matrix\n",
    "        return cpp_fwd(lin.weights, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f93926a-16db-403e-a2c0-e30bba55e59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin = CustomLinearCpp(2,3)\n",
    "x = torch.ones(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc53ef3a-8904-4222-a010-08a4c948aec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 2., 2.]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = lin(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2281a2e9-b977-49da-9ed6-7fb18f08736c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.sum().backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3c2c27-2780-417c-990f-c76506aeecaa",
   "metadata": {},
   "source": [
    "Hmm, I expected a runtime error, because I thought the backwards-function isn't known."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8591fa59-d2d9-463f-8191-301e764d8ce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None,\n",
       " tensor([[1., 1.],\n",
       "         [1., 1.],\n",
       "         [1., 1.]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad, lin.weights.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf487308-7ce8-4ecf-a396-43724bf995b3",
   "metadata": {},
   "source": [
    "Interestingly, the grads could be computed. It seems `torch::mm` in cpp has a defined backwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafde2bf-d30c-4dc0-a95d-83b69e77fab9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a067d4-49a0-4d02-9c75-157164d87e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLinFunction(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, weights, x):\n",
    "        ctx.save_for_backward(weights, x)\n",
    "        return cpp_fwd(weights, x)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, d):\n",
    "        d_x, d_weights = cpp_bwd(d, *ctx.saved_tensors) # need to destructure into 2 elems, otherwise grad engine thinks we're returning 1 grad, but expects 2\n",
    "        return d_x, d_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de66820b-1fb7-402d-be1d-535e2c2ce233",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLinearCpp(nn.Module):\n",
    "    def __init__(self, cin, cout):\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(torch.ones(cout, cin))\n",
    "\n",
    "    def forward(self, x):\n",
    "        if len(x.shape)==1: x = x.unsqueeze(0) # cpp_fwd expects x to be a matrix\n",
    "        return CustomLinFunction.apply(self.weights, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8da66f2-2944-4ed0-8ab7-79bc0e1d60f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin = CustomLinearCpp(2,3)\n",
    "x = torch.ones(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74dda08e-5a90-47ac-b394-416674c9cd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = lin(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a213528-2524-40cd-80a5-81ef39b05cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f5d68d-0b22-4c35-8925-d4c67f5b2be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.grad, lin.weights.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293913d4-55de-4cbf-94e2-9a66fc492f19",
   "metadata": {},
   "source": [
    "Note: I verified `lin.weights.grad` changes when the cpp-backward is changed (eg doubled)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b15327f-9de2-4a49-9451-cd9c9d099ae6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cf967c-237d-4844-ba2c-5ab6bfebd689",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72a9d033-bb59-4952-9556-447258abb8cd",
   "metadata": {},
   "source": [
    "## 3. Fwd and Bwd in Cuda:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73ac823-9b4c-4b11-8cf3-6e287f23f85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_lin_cuda = load(\n",
    "    name='custom_lin_cuda', \n",
    "    sources=['custom_linear_cuda.cpp', 'custom_linear.cu'],\n",
    "    build_directory='tmp',\n",
    "    verbose=True\n",
    ")\n",
    "cuda_fwd = custom_lin_cuda.forward\n",
    "cuda_bwd = custom_lin_cuda.backward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607889cf-e585-4d4b-b108-691a587576e9",
   "metadata": {},
   "source": [
    "No we can use `cuda_fwd` / `cuda_bwd` the same way as `cpp_fwd` / `cpp_bwd` above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e9fc50-08d6-4b43-8914-63a87dc11a29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
