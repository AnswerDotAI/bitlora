{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e7e9e9c-e6b5-450f-afd9-2a3e8180eca2",
   "metadata": {},
   "source": [
    "(Started) implementation of a naive triton kernel for hqq-fwd, for axis=1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd46406-af19-4cfb-935c-edbbfba72cd8",
   "metadata": {},
   "source": [
    "**Naming convention:**\n",
    "- bsx  = block size along axis x\n",
    "- idx  = index along axis x\n",
    "- nidx = number of chunks along axis x\n",
    "\n",
    "eg if len(x) = 10, and we divide x into chunks of size 2 (so 10/2=5 chunks), and are selecting the 4rd chunk (ie 6th and 7th value), then bsx=2, idx=4, nidx=5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d059eadd-1891-4f83-bbb7-a4e57dffd990",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "\n",
    "from torch import tensor, cat, int32, float16 as fp16, bfloat16 as bf16, isclose\n",
    "from tabulate import tabulate\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.environ['TRITON_INTERPRET'] = '1'\n",
    "\n",
    "import triton\n",
    "import triton.language as tl\n",
    "import triton_util as tu\n",
    "\n",
    "const = tl.constexpr\n",
    "cdiv, breakpoint_once, print_once = tu.cdiv, tu.breakpoint_once, tu.print_once\n",
    "\n",
    "torch.set_printoptions(linewidth=200, precision=2, sci_mode=False)\n",
    "np.set_printoptions(linewidth=200, precision=2) # for triton simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce2cc988-3e0b-47f5-99b7-abd172fc674e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = fp16 # can't use bf16 with triton simulator, as numpy doesn't support bf16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "195dd2c5-5deb-4d85-9245-8d6c6bfcec3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_p = 7, ng = 128, ng2 = 1\n"
     ]
    }
   ],
   "source": [
    "b,m,r,n = 2,128,32,64 # batch size, out, lora rank, in\n",
    "gz, gz2, pz = 64, 128, 10    # group size, group size for quanting zero & scale, pack size (needs to be 10, as we pack 10 x 3bit -> 32bit)\n",
    "\n",
    "n_p = cdiv(gz,  pz) # number of packs per group (can't name it np due to numpy)\n",
    "ng  = cdiv(m*n, gz) # number of groups\n",
    "ng2 = cdiv(ng , gz2)# number of groups for quanting zero/scale\n",
    "\n",
    "print(f'{n_p = }, {ng = }, {ng2 = }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2eba3267-f9b2-4d9b-a5ae-c4f0f142fbee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_groups (128) divides group_size_2 (128) âœ“\n"
     ]
    }
   ],
   "source": [
    "assert ng%gz2==0, f'num_groups ({ng}) needs to divide group_size_2 ({gz2}) for quanting of zero & scale to work'\n",
    "print(f'num_groups ({ng}) divides group_size_2 ({gz2}) âœ“')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc3509b3-b21f-44c7-99f3-1a29e7e8552f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ones(*shape): return torch.ones(*shape, dtype=dtype, device='cuda')\n",
    "\n",
    "X, A, B = ones(b,n), ones(r,n), ones(m,r)\n",
    "\n",
    "mag = ones(m) # magnitude\n",
    "Î± = 0.9\n",
    "\n",
    "scale_q, zero_q = ones(gz2, ng2), ones(gz2, ng2)\n",
    "\n",
    "s_scale, s_zero, z_scale, z_zero = ones(1, ng2), ones(1, ng2), ones(1, ng2), ones(1, ng2)\n",
    "\n",
    "packed_value = (1 << 29) + (1 << 26)  # first 2 packs set to 1, other 0: 001 001 00000000000000000000000000\n",
    "\n",
    "bit_repr = [int(o) for o in format(packed_value & 0xFFFFFFFF, '032b')]\n",
    "assert sum(bit_repr)==2 # only 2 ones...\n",
    "assert (bit_repr[2], bit_repr[5])==(1,1) # ... at location 2 and 5 \n",
    "\n",
    "W_qp = torch.full((n_p,ng), packed_value, dtype=int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57395360-1367-4820-affe-5aafe7a16937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[603979776, 603979776, 603979776],\n",
       "        [603979776, 603979776, 603979776],\n",
       "        [603979776, 603979776, 603979776]], dtype=torch.int32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_qp[:3,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ec083dc-91ee-4e43-9128-65c168fe31c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_shape = (128, 64), zero_scale_shape = (1, 128)\n"
     ]
    }
   ],
   "source": [
    "W_shape = (m, n)\n",
    "zero_scale_shape = (1, ng)\n",
    "print(f'{W_shape = }, {zero_scale_shape = }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96a3fbf-5679-4ac1-a976-0ea0c7944662",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29dd824e-45eb-4908-94d6-dd622447580d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assert_close(out, expected, do_print=True, atol=1e-5):\n",
    "    if do_print:\n",
    "        print(out)\n",
    "        print(expected)\n",
    "    assert torch.isclose(out, expected,atol=atol).all(), 'Not close ðŸ¤”'\n",
    "    print('Equal âœ…')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e4227b-1c5f-4d26-9130-ec34360bf248",
   "metadata": {},
   "source": [
    "### Sub-Kernel 1: Load & Dequant zero / scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13feb41a-99af-4d54-8c7c-f8535977d3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.jit\n",
    "def dequant_zero_or_scale(vals_ptr, zero_ptr, scale_ptr, gz2: const, ng2: const, shape: const):\n",
    "    vals_q = tu.load_full_2d(vals_ptr,  sz0=gz2, sz1=ng2, stride0=ng2) # quanted zero/scale values; ~ (gz2, ng2)\n",
    "    zero   = tu.load_full_1d(zero_ptr,  sz=ng2)                        # zero  of zero/scale;       ~ (ng2)\n",
    "    scale  = tu.load_full_1d(scale_ptr, sz=ng2)                        # scale of zero/scale;       ~ (ng2)\n",
    "    vals = (vals_q-zero)*scale\n",
    "    return vals.reshape(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7f1cc2d-c2e1-4871-b478-97ebd2dcdd38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@triton.jit\n",
    "def test_dequant_zero_or_scale(out_ptr, vals_ptr, zero_ptr, scale_ptr, gz2: const, ng2: const, shape: const):\n",
    "    out = dequant_zero_or_scale(vals_ptr, zero_ptr, scale_ptr, gz2, ng2, shape)\n",
    "    tu.store_full_2d(out, out_ptr, shape[0], shape[1], stride0=shape[1])\n",
    "\n",
    "zvals = torch.ones((gz2, ng2), device='cuda', dtype=dtype) * 1\n",
    "zzero = torch.ones((1,   ng2), device='cuda', dtype=dtype) * 2\n",
    "zscale= torch.ones((1,   ng2), device='cuda', dtype=dtype) * 3\n",
    "out  = torch.zeros((ng, 1),  device='cuda', dtype=dtype)\n",
    "\n",
    "test_dequant_zero_or_scale[(1,)](out, zvals, zzero, zscale, gz2, ng2, (ng,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0920009-8167-4b65-a4fc-a8729dcc9f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equal âœ…\n"
     ]
    }
   ],
   "source": [
    "assert_close(out, (zvals-zzero)*zscale, do_print=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44fdf0d-b64a-4165-995c-a75e4d7fa824",
   "metadata": {},
   "source": [
    "### Sub-Kernel 2: Load, unpack W_qp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75b442a4-6f73-47d8-a43b-a3696459a519",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hqq.core.bitpack import BitPack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79a44c1a-79d1-4a14-85cc-145dc1a66af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "\n",
    "@triton.jit\n",
    "def load_W_q(ptr, bsm: const, idm: const, m: const, n: const, gz: const, pz: const):\n",
    "    '''Load selected rows from W_qp (and all cols)'''\n",
    "\n",
    "    if DEBUG: print_once('---- Running load_W_q ----')\n",
    "    if DEBUG: print_once(f'bsm = {bsm}, idm = {idm}, m = {m}, n = {n}, gz = {gz}, pz = {pz}')\n",
    "    \n",
    "    offs   = tu.offset_1d(bsm, idm)  # rows of W\n",
    "    if DEBUG: print_once(f'W rows = {offs}')    \n",
    "    if DEBUG: print_once(f'grouping multiplier = {n/gz}')    \n",
    "    \n",
    "    offs_q = tu.offset_1d(bsm*(n//gz), idm) # rows of W_q ; note: n/gz is integer    \n",
    "    if DEBUG: print_once(f'W_q rows = {offs_q}')    \n",
    "    \n",
    "    npacks = cdiv(m*n//gz, 10)         # number of packed values\n",
    "    if DEBUG: print_once(f'npacks = {npacks}')    \n",
    "    \n",
    "    offs0  = offs_q % npacks           # rows of W_qp\n",
    "    if DEBUG: print_once(f'W_qp rows = {offs0}')    \n",
    "    \n",
    "    shifts = 27 - 3*(offs_q // npacks) # right-shifts needed to unpack correctly, for each row    \n",
    "    if DEBUG: print_once(f'shifts = {shifts}')    \n",
    "    \n",
    "    offs1 = tl.arange(0, gz) # all cols\n",
    "    if DEBUG: print_once(f'offs1 = {offs1}')    \n",
    "    \n",
    "    w_pq_offs = tu.offset_2d(offs0, offs1, stride0=gz)\n",
    "    if DEBUG: print_once(f'w_pq_offs =\\n{w_pq_offs}')    \n",
    "\n",
    "    w_pq_mask = tu.mask_2d  (offs0, offs1, max0=m*n//gz, max1=gz)\n",
    "    if DEBUG: print_once(f'w_pq_mask =\\n{w_pq_mask}')    \n",
    "\n",
    "    vals = tl.load(ptr + w_pq_offs, w_pq_mask)\n",
    "    if DEBUG: print_once(f'vals =\\n{vals}')    \n",
    "\n",
    "    shifted_vals = vals >> shifts[:,None] & 0b111\n",
    "    if DEBUG: print_once(f'shifted_vals =\\n{shifted_vals}')    \n",
    "    \n",
    "    return shifted_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17084d4d-b93a-43de-8182-354cb7d28906",
   "metadata": {},
   "source": [
    "Let's test it with random 3bit values, for a weight matrix W of size `8x4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33070449-7a18-46a1-90fd-e4743a1b9e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.jit\n",
    "def test_load_W_q(out_ptr, W_qp_ptr, idm: const, bsm: const, m: const, n: const, gz: const, pz: const):\n",
    "    W_q = load_W_q(W_qp_ptr, bsm, idm, m, n, gz, pz)\n",
    "    tu.store_full_2d(W_q, out_ptr, bsm, gz, gz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ddcd161f-b09f-4c97-8bf7-069acbd30794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 4]), torch.Size([1, 4]), 8, 4, 4, 10)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m,n=8,4\n",
    "gz = 4\n",
    "\n",
    "rand = torch.randint(low=0, high=7, size=(m,n), device='cuda', dtype=dtype)\n",
    "rand_packed = BitPack.pack_3bit_32(rand.reshape(-1,gz))\n",
    "rand.shape, rand_packed.shape, m, n, gz, pz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fcf4bbfc-a91a-4cd3-bb1e-ea764cb10e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- idm = 0\n",
      "tensor([[4., 5., 4., 0.],\n",
      "        [5., 3., 1., 5.]], device='cuda:0', dtype=torch.float16)\n",
      "tensor([[4., 5., 4., 0.],\n",
      "        [5., 3., 1., 5.]], device='cuda:0', dtype=torch.float16)\n",
      "Equal âœ…\n",
      "-- idm = 1\n",
      "tensor([[6., 0., 0., 4.],\n",
      "        [1., 1., 3., 5.]], device='cuda:0', dtype=torch.float16)\n",
      "tensor([[6., 0., 0., 4.],\n",
      "        [1., 1., 3., 5.]], device='cuda:0', dtype=torch.float16)\n",
      "Equal âœ…\n"
     ]
    }
   ],
   "source": [
    "bsm=2\n",
    "for idm in [0,1]:\n",
    "    print(f'-- idm = {idm}')\n",
    "    small_bsm = 2\n",
    "    out = torch.zeros(bsm*(n//gz), gz, device='cuda')\n",
    "    test_load_W_q[(1,1)](out, rand_packed, idm, bsm, m, n, gz, pz)\n",
    "    assert_close(out.half(), rand[idm*bsm:(idm+1)*bsm,:].reshape(-1,gz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39784284-bee3-4b71-8b2b-2f357bfc6fb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29b08664-0ae9-477f-ad2d-b19e32ac8f94",
   "metadata": {},
   "source": [
    "### Sub-Kernel 3: Dequant W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8fb9751a-c0f5-4d15-a175-f39df0dc6e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.jit\n",
    "def dequant_W(W_q, zero, scale, bsm: const, n:const):\n",
    "    return ((W_q-zero)*scale).reshape(bsm,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e0275f55-cfc3-451c-83d9-c71155f4916e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.jit\n",
    "def test_dequant_W(out_ptr, vals_ptr, zero_ptr, scale_ptr, bsm: const, n: const, gz: const):\n",
    "    W_q   = tu.load_full_2d(vals_ptr,  bsm*n//gz, gz, gz)\n",
    "    zero  = tu.load_full_2d(zero_ptr,  bsm*n//gz, 1,   1)\n",
    "    scale = tu.load_full_2d(scale_ptr, bsm*n//gz, 1,   1)\n",
    "\n",
    "    W = dequant_W(W_q, zero, scale, bsm, n)\n",
    "\n",
    "    tu.store_full_2d(W, out_ptr, bsm, n, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e21dddc-589e-4ae1-8bad-f493a6e07f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bsm = 2\n",
    "m,n=8,4\n",
    "gz = 2\n",
    "\n",
    "vals = torch.ones((bsm*n//gz, gz), device='cuda', dtype=dtype) * 1\n",
    "zero = torch.ones((bsm*n//gz,  1), device='cuda', dtype=dtype) * 2\n",
    "scale= torch.ones((bsm*n//gz,  1), device='cuda', dtype=dtype) * 3\n",
    "out  = torch.zeros((bsm, n),  device='cuda', dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a46b5c42-8073-4f4a-bc78-c18b50a05230",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dequant_W[(1,)](out, vals, zero, scale, bsm, n, gz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cef1896d-3e6d-45c4-9145-7701b97d50a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-3., -3., -3., -3.],\n",
      "        [-3., -3., -3., -3.]], device='cuda:0', dtype=torch.float16)\n",
      "tensor([[-3., -3., -3., -3.],\n",
      "        [-3., -3., -3., -3.]], device='cuda:0', dtype=torch.float16)\n",
      "Equal âœ…\n"
     ]
    }
   ],
   "source": [
    "assert_close(out, ((vals-zero)*scale).reshape(-1,n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccef134-8773-45d3-bb2c-42fe9492c166",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a0a04f4-cee3-4bc9-b300-232db3864684",
   "metadata": {},
   "source": [
    "### Sub-Kernel 4: `x@w.t`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d1e2ab5e-dbe5-4a20-b811-0664983eb4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input:\n",
    "# 1. x[b-chunk,:]\n",
    "# 2. w[m-chunk,:]\n",
    "# output x@w.t[b-chunk,m-chunk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c2c95728-139e-49bb-a944-c167efdae025",
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.jit\n",
    "def batched_matmul(\n",
    "    x_ptr, w_ptr,                       # pointers\n",
    "    bsb: const, bsm: const, bsn: const, # block sizes\n",
    "    idb, idm,                           # block indices\n",
    "    b:const, m:const, n:const,          # matrix sizes\n",
    "    swizzle_group_sz: const \n",
    "):\n",
    "    # determine location of block in grouped ordering - swizzle!     \n",
    "    nidb, nidm = cdiv(b,bsb), cdiv(m,bsm)\n",
    "    idb, idm = tl.swizzle2d(idb, idm, nidb, nidm, swizzle_group_sz)\n",
    "    # 1d offets along b,m,n axes\n",
    "    offs_b = tu.offset_1d(bsb, idb)\n",
    "    offs_m = tu.offset_1d(bsm, idm)\n",
    "    offs_n = tu.offset_1d(bsn, 0)\n",
    "    # 2d offsets of x, w\n",
    "    offs_x = x_ptr + tu.offset_2d(offs_b, offs_n, n)\n",
    "    offs_w = w_ptr + tu.offset_2d(offs_m, offs_n, n)\n",
    "    # initialize and iteratively update accumulator\n",
    "    acc = tl.zeros((bsb, bsm), dtype=tl.float32)\n",
    "    for _ in range(0, n, bsn):\n",
    "        x = tl.load(offs_x)\n",
    "        w = tl.load(offs_w)\n",
    "        acc += tl.dot(x, w.trans(), allow_tf32=False) # allow_tf32 must be set to False for older GPUs, otherwise won't compile\n",
    "        # increase offsets, so next iteration loads next chunks\n",
    "        offs_x += bsn\n",
    "        offs_w += bsn\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b21d465-47c6-4533-8d90-0e344a5ee5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.jit\n",
    "def test_batched_mamtul(\n",
    "    out_ptr,\n",
    "    x_ptr, w_ptr,                       # pointers\n",
    "    bsb: const, bsm: const, bsn: const, # block sizes\n",
    "    idb, idm,                           # block indices\n",
    "    b:const, m:const, n:const,          # matrix sizes\n",
    "    swizzle_group_sz: const \n",
    "):\n",
    "    out = batched_matmul(x_ptr, w_ptr, bsb, bsm, bsn, idb, idm, b, m, n, swizzle_group_sz)\n",
    "    tu.store_full_2d(out, out_ptr, bsb, bsm, bsm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c5dbb5-aa0c-41ff-b7f6-0c8f83febbec",
   "metadata": {},
   "source": [
    "Test it with small 1-matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216525bb-d38e-46ac-afb6-f4c461bf03da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a4c31570-ef69-4c2c-870c-3a557c3b9409",
   "metadata": {},
   "outputs": [],
   "source": [
    "b,m,n = 16, 16, 16\n",
    "\n",
    "bsb,bsm,bsn = 16,16,16 # tl.dot requires all axes to be >= 16\n",
    "\n",
    "x = ones(b,n)\n",
    "w = ones(m,n)\n",
    "out = torch.zeros((bsb,bsm),dtype=dtype, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "45e57899-b102-4c01-aac2-ea3bf770d113",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batched_mamtul[(cdiv(b,bsb), cdiv(m,bsm))](out, x, w, bsb, bsm, bsn, 0, 0, b,m,n, swizzle_group_sz=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5a8ceab5-a0b4-4757-b47a-e1dcc8f9c6be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equal âœ…\n"
     ]
    }
   ],
   "source": [
    "assert_close(out, x@w.t(), do_print=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f470645b-64cc-4183-8dce-b108916a11e1",
   "metadata": {},
   "source": [
    "Test it with larger 1-matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b15e76d1-5b95-485b-bd1d-a09b45e92f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "b,m,n = 128, 128, 128\n",
    "\n",
    "bsb,bsm,bsn = 32,32,16 # tl.dot requires all axes to be >= 16\n",
    "\n",
    "x = ones(b,n)\n",
    "w = ones(m,n)\n",
    "\n",
    "out = torch.zeros((b,m), dtype=dtype, device='cuda')\n",
    "\n",
    "for idb, idm in product(range(cdiv(b,bsb)), range(cdiv(m,bsm))):\n",
    "    out_patch = torch.zeros((bsb,bsm),dtype=dtype, device='cuda')\n",
    "    test_batched_mamtul[(cdiv(b,bsb), cdiv(m,bsm))](out_patch, x, w, bsb, bsm, bsn, idb, idm, b,m,n, swizzle_group_sz=2)\n",
    "\n",
    "    min_b =     idb*bsb\n",
    "    max_b = (idb+1)*bsb\n",
    "    min_m =     idm*bsm\n",
    "    max_m = (idm+1)*bsm\n",
    "    \n",
    "    max_b = min(max_b,b)\n",
    "    max_m = min(max_m,m)\n",
    "\n",
    "    out[min_b:max_b, min_m:max_m] = out_patch[:max_b-min_b, :max_m-min_m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "10b53fa9-ce92-41e2-8aec-7d89f8c37e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equal âœ…\n"
     ]
    }
   ],
   "source": [
    "assert_close(out, x@w.t(), do_print=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05948e03-8a8d-4c2c-bd58-e73c748a5091",
   "metadata": {},
   "source": [
    "Test it with larger random matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73393bcf-c20e-48ff-b619-d88dfbc21ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Note: The "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "19e92a88-7380-4a09-812d-72e920ce428b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from triton.language.standard.py\n",
    "def swizzle2d(i, j, size_i, size_j, size_g):\n",
    "    ij = i * size_j + j\n",
    "    size_gj = size_g * size_j\n",
    "    group_id = ij // size_gj\n",
    "    off_i = group_id * size_g\n",
    "    size_g = min(size_i - off_i, size_g)\n",
    "    new_i = off_i + (ij % size_g)\n",
    "    new_j = (ij % size_gj) // size_g\n",
    "    return new_i, new_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7dfc9dad-4d74-41e0-928c-e842ab33c4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "b,m,n = 32, 32, 32\n",
    "\n",
    "bsb,bsm,bsn = 16,16,16 # tl.dot requires all axes to be >= 16\n",
    "\n",
    "x = torch.rand((b,n), dtype=dtype, device='cuda')\n",
    "w = torch.rand((m,n), dtype=dtype, device='cuda')\n",
    "\n",
    "out = torch.zeros((b,m), dtype=dtype, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2d4d4ed2-6c5d-4fe5-9418-48b6e0882e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equal âœ…\n"
     ]
    }
   ],
   "source": [
    "nidb, nidm = cdiv(b,bsb), cdiv(m,bsm)\n",
    "for idb, idm in product(range(nidb), range(nidm)):\n",
    "    out_patch = torch.zeros((bsb,bsm),dtype=dtype, device='cuda')\n",
    "    test_batched_mamtul[(cdiv(b,bsb), cdiv(m,bsm))](out_patch, x, w, bsb, bsm, bsn, idb, idm, b,m,n, swizzle_group_sz=2)\n",
    "\n",
    "    idb, idm = swizzle2d(idb, idm, nidb, nidm, size_g=2)\n",
    "    \n",
    "    min_b =     idb*bsb\n",
    "    max_b = (idb+1)*bsb\n",
    "    min_m =     idm*bsm\n",
    "    max_m = (idm+1)*bsm\n",
    "    \n",
    "    max_b = min(max_b,b)\n",
    "    max_m = min(max_m,m)\n",
    "\n",
    "    out[min_b:max_b, min_m:max_m] = out_patch[:max_b-min_b, :max_m-min_m]\n",
    "\n",
    "assert_close(out, x@w.t(), do_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dfd19e4f-d424-4b21-a776-1e6fc7cd3b9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "err = (out-x@w.t()).abs().cpu()\n",
    "plt.imshow(err)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69f8476-3444-4712-882b-5101893210e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "26dc22b0-d43f-4040-bd2c-b707ca9a8e76",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Sub-Kernel 5: `x@a.t@b.t`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f5e49c-280a-4f49-9322-35192cfd539c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdb98c6-6143-4a7a-9d83-a4866149e90f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ebcd9804-61d9-44f1-8f92-e8e06cf70824",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Sub-Kernel 6: colnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21510753-a3e5-4945-b312-4d7b615ebf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2d71ca-fb8a-4303-af1a-b82d38abead3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17ed5b62-9386-40b9-936f-95bee200af22",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Sub-Kernel 7: `* Î±, Î², mag, 1/colnorm`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96066993-3e6c-447f-a2d9-8b615421fe51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8462b060-b93e-4dfd-ada1-f3c607841246",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0a00620-499e-48c7-8da4-aee55a6389c7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Full Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0342e221-695d-4fb5-8ffe-8b7f0bdf732d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fwd_op(fwd_k, bsb, bsm, bsr, bsn):\n",
    "    # for simplicity, following vars are used from closure & will instead be passed in actual op:\n",
    "    #   X, A, B, W_qp, scale_q, zero_q,\n",
    "    #   mag, s_scale, s_zero, z_scale, z_zero\n",
    "    #   Î±\n",
    "    #   W_shape, zero_scale_shape \n",
    "    # these vars will be computed from in actual op, but are also used from closure for simplicity\n",
    "    #   b,m,r,n\n",
    "\n",
    "    Y = torch.zeros((b,m),dtype=bf16, device='cuda')\n",
    "    assert_tensors_gpu_ready(Y, X, A, B, mag, scale_q, zero_q, s_scale, s_zero, z_scale, z_zero, W_qp)\n",
    "\n",
    "    grid = (cdiv(b, bsb), cdiv(m, bsm))\n",
    "    print(f'Launching grid of size {grid}')\n",
    "    \n",
    "    fwd_k[grid](\n",
    "        # input matrices\n",
    "        X, A, B, W_qp, scale_q, zero_q, \n",
    "        # input vectors\n",
    "        mag, s_scale, s_zero, z_scale, z_zero,\n",
    "        # input scalars\n",
    "        Î±,\n",
    "        # output matrix\n",
    "        Y,\n",
    "        # dimensions\n",
    "        b,m,r,n,\n",
    "        # grouping / packing configs\n",
    "        gz, gz2, pz,\n",
    "        # shapes to undo grouping\n",
    "        W_shape, zero_scale_shape,\n",
    "        # block sizes\n",
    "        bsb, bsm, bsr, bsn\n",
    "        # strides\n",
    "        # todo\n",
    "    )\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8e11e1-e5be-4ed7-b20f-23544ff6fd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # total todo:\n",
    "# dequant zero & scale\n",
    "# unpack w\n",
    "# dequant w    \n",
    "# x@w.t\n",
    "# x@a.t@b.t\n",
    "# build colnorm\n",
    "# times alpha, mag, 1/colnorm\n",
    "\n",
    "@triton.jit\n",
    "def forward_k(\n",
    "    # input matrices\n",
    "    X_ptr, A_ptr, B_ptr, W_qp_ptr, scale_q_ptr, zero_q_ptr,\n",
    "    # input vectors\n",
    "    mag_ptr, s_scale_ptr, s_zero_ptr, z_scale_ptr, z_zero_ptr,\n",
    "    # input scalars\n",
    "    Î±,\n",
    "    # output matrix\n",
    "    Y_ptr,\n",
    "    # dimensions\n",
    "    b: tl.constexpr, m: tl.constexpr, r: tl.constexpr, n: tl.constexpr,\n",
    "    # grouping / packing configs\n",
    "    gz: tl.constexpr, gz2: tl.constexpr, pz: tl.constexpr,\n",
    "    # shapes to undo grouping\n",
    "    W_shape: tl.constexpr, zero_scale_shape: tl.constexpr, \n",
    "    # block sizes\n",
    "    bsb: tl.constexpr, bsm: tl.constexpr, bsr: tl.constexpr, bsn: tl.constexpr,\n",
    "    # strides\n",
    "    # todo\n",
    "):\n",
    "    tl.static_assert(m%gz and n%gz, f'group_size ({gz}) must divide m ({m}) and n ({n})')\n",
    "    \n",
    "    pid0, pid1 = tl.program_id(0), tl.program_id(1) # blocks correspond to chunking of b and m axes\n",
    "\n",
    "    n_p: tl.constexpr  = cdiv(gz,  pz)  # number of packs per group (can't name it np due to numpy)\n",
    "    ng:  tl.constexpr  = cdiv(m*n, gz)  # number of groups\n",
    "    ng2: tl.constexpr  = cdiv(ng,  gz2) # number of groups for quanting zero/scale\n",
    "    \n",
    "    # # dequant zero & scale\n",
    "    zero  = dequant_zero_or_scale(zero_q_ptr,  z_zero_ptr, z_scale_ptr,  gz2, ng2, shape=zero_scale_shape)\n",
    "    scale = dequant_zero_or_scale(scale_q_ptr, s_zero_ptr, s_scale_ptr,  gz2, ng2, shape=zero_scale_shape)\n",
    "    # # unpack w\n",
    "    qp_row_lo, qp_row_hi = rows_in_W_pq(bsm, pid1, m, n, gz, pz)        # determine which rows of W_qp are relevant\n",
    "    w_qp = load_W_qp(W_qp_ptr, qp_row_lo, qp_row_hi, row_max=n_p, ng=ng) # load those rows (and all cols)\n",
    "\n",
    "    breakpoint_once()\n",
    "\n",
    "    \n",
    "    # dequant w\n",
    "    \n",
    "    # x@w.t\n",
    "    # x@a.t@b.t\n",
    "    # build colnorm\n",
    "    # times alpha, mag, 1/colnorm\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8d018b-18b6-468d-b6ad-d96c840619a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_sizes = dict(bsb=2, bsm=2, bsr=2, bsn=2)\n",
    "fwd_op(forward_k, **block_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f68814b-143c-4e38-9fd6-75364fc57ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise ValueError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51adac06-179f-4b8e-937e-21037dc5256a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbec792-2bf0-4a0d-9957-1ae8c42c24e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3b6231-985d-4439-aec9-25ce6d65d818",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qp_rows(lo, hi, pz, gz, m, n):\n",
    "    assert m%gz==n%gz==0, 'gz must divide m and n'\n",
    "    qlo, qhi = lo*n//gz, hi*n//gz\n",
    "    npacks = cdiv((m*n//gz), 10)\n",
    "    plo, phi = qlo%npacks, qhi%npacks\n",
    "    print(f'groups = {int(m*n/gz)}, packs = {npacks}')\n",
    "    print(f'rows: {lo},{hi}\\nquanted rows: {qlo}, {qhi}\\npacked rows: {plo}, {phi}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038946fe-c490-4d8d-9065-af5076400042",
   "metadata": {},
   "outputs": [],
   "source": [
    "qp_rows(10, 14, pz, gz, m, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1366f42-db26-4bc9-b202-49e48f643d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "m,n,gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8666dae-10cf-49b9-a114-7e4b177b0ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdiv??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5c4e8f-62aa-47e7-a851-defc7ad2a2d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
