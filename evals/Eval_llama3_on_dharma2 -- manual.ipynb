{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1be71e8-1554-4cb4-8c14-0a6439dac1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c00d822-e4ee-4de8-a8cf-798b93e9a3f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ac0e114c67149e698e50c7c7996edd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c0269a-5d53-4617-8770-2b5e1fc7dcde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03e7f8ec-55fa-489c-995c-f6dad74278d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lm_eval\n",
    "from lm_eval.evaluator_utils import get_task_list, get_sample_size\n",
    "from lm_eval.tasks.__init__ import get_task_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7694e434-4422-4029-a7ae-c211435a025f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a81631e7-bf9a-4cc3-9e8f-79f7c7120678",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-24:19:40:34,739 WARNING  [task.py:322] [Task: dharma2] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.\n",
      "2024-04-24:19:40:34,740 WARNING  [task.py:322] [Task: dharma2] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'dharma2': ConfigurableTask(task_name=dharma2,group_name=None,output_type=generate_until,num_fewshot=None,num_samples=300)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_dict = get_task_dict(['dharma2'])\n",
    "task_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9df075-9f58-4fb9-8c85-43558f8361e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33831684-74a1-49a2-9081-feb56aa7cb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "args = argparse.Namespace(\n",
    "    model='hf',\n",
    "    model_args='pretrained=meta-llama/Meta-Llama-3-8B',\n",
    "    tasks='dharma2',\n",
    "    device='cuda:0',\n",
    "    batch_size='auto',\n",
    "    # set limit to None for full test\n",
    "    limit=2, # \n",
    "    # defaults \n",
    "    num_fewshot=None,\n",
    "    max_batch_size=None,\n",
    "    output_path=None,\n",
    "    use_cache=None,\n",
    "    cache_requests=None,\n",
    "    check_integrity=False,\n",
    "    write_out=False,\n",
    "    log_samples=False,\n",
    "    show_config=False,\n",
    "    include_path=None,\n",
    "    gen_kwargs=None,\n",
    "    verbosity='INFO',\n",
    "    wandb_args='',\n",
    "    predict_only=False,\n",
    "    seed=[0, 1234, 1234],  # Adjust if needed\n",
    "    trust_remote_code=False,\n",
    "    # default function params\n",
    "    rewrite_requests_cache = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8821b324-a46c-46de-8539-2b64635d24f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "656ed051-8f55-453e-8c86-be241c79b271",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# tracks all Instances/requests a model must generate output on.\n",
    "requests = defaultdict(list)\n",
    "\n",
    "# stores the amount to pad out reqs per req. type so that\n",
    "# number of fwd passes per distributed rank is equal\n",
    "padding_requests = defaultdict(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa132b23-4401-4a18-98a7-5131f4a5a470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {'dharma2': []})\n",
      "[TaskOutput(task_name=dharma2, group_name=None, version=1.0,n_shot=Nonetask_alias=None, group_alias=None)]\n"
     ]
    }
   ],
   "source": [
    "task_hierarchy, eval_tasks = get_task_list(task_dict)\n",
    "print(task_hierarchy)\n",
    "print(eval_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3d25060-af09-4ab8-80e0-4981057bdb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not args.log_samples:\n",
    "    if not all(\n",
    "        \"bypass\" not in getattr(task_output.task, \"_metric_fn_list\", {}).keys()\n",
    "        for task_output in eval_tasks\n",
    "    ):\n",
    "        raise ValueError(\"log_samples must be True for 'bypass' metric-only tasks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e3462cc-9803-49f2-a9ed-861144058531",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-24:19:41:00,348 INFO     [huggingface.py:164] Using device 'cuda:0'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "020a2380b10e451f907c494f668f5f51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "387b49247034470592c4df680fd47557",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c143df97b88446cb8e32d77aed9f1253",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/177 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "lm = lm_eval.api.registry.get_model(args.model).create_from_arg_string(\n",
    "    args.model_args,\n",
    "    {\n",
    "        \"batch_size\": args.batch_size,\n",
    "        \"max_batch_size\": args.max_batch_size,\n",
    "        \"device\": args.device,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78fa5cf-e776-457d-9b0d-d08dc29df35e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6197a521-db18-467c-ba5e-e476793db451",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for task_output in eval_tasks:\n",
    "task_output = eval_tasks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7b12b32-ce4c-4cd2-b747-24015496b7c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConfigurableTask(task_name=dharma2,group_name=None,output_type=generate_until,num_fewshot=None,num_samples=300)\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "task = task_output.task\n",
    "print(task)\n",
    "limit = get_sample_size(task, args.limit)\n",
    "print(limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2838b52b-6d13-44f9-900c-bba70090d4b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f99f945-3d40-4c7d-8a42-c6e617892afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-24:19:41:18,752 INFO     [task.py:395] Building contexts for dharma2 on rank 0...\n",
      "100%|██████████| 2/2 [00:00<00:00, 18477.11it/s]\n"
     ]
    }
   ],
   "source": [
    "task.build_all_requests(\n",
    "    limit=limit,\n",
    "    rank=lm.rank,\n",
    "    world_size=lm.world_size,\n",
    "    cache_requests=args.cache_requests,\n",
    "    rewrite_requests_cache=args.rewrite_requests_cache,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b771beef-25dc-4817-924d-8cddf87e5392",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4948615-35e6-4ac4-9646-2ead8f2fff63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate Instances by LM method requested to get output.\n",
    "for instance in task.instances:\n",
    "    reqtype = instance.request_type\n",
    "    requests[reqtype].append(instance)\n",
    "\n",
    "assert lm.world_size == 1\n",
    "# if lm.world_size > 1: # if is never entered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a76fdd58-709d-4429-9032-41d73875636a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(requests['generate_until'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b53d83-cf22-41c0-8abc-c1697a5614d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "887cdcf4-4276-46dc-b3fa-ed2327cbf0bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running generate_until requests:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed argument batch_size = auto. Detecting largest batch size\n",
      "Determined Largest batch size: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:497: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Running generate_until requests: 100%|██████████| 2/2 [00:11<00:00,  5.96s/it]\n"
     ]
    }
   ],
   "source": [
    "### Run LM on inputs, get all outputs ###\n",
    "# execute each type of request\n",
    "for reqtype, reqs in requests.items():\n",
    "    # create `K` copies of each request `req` based off `K = req.repeats`\n",
    "    cloned_reqs = []\n",
    "    for req in reqs:\n",
    "        cloned_reqs.extend([req] * req.repeats)\n",
    "\n",
    "    if (lm.world_size > 1) and (padding_requests[reqtype] > 0):\n",
    "        for _ in range(padding_requests[reqtype]):\n",
    "            cloned_reqs.extend([req] * req.repeats)\n",
    "\n",
    "    # run requests through model\n",
    "    resps = getattr(lm, reqtype)(cloned_reqs)\n",
    "\n",
    "    # put responses from model into a list of length K for each request.\n",
    "    for x, req in zip(resps, cloned_reqs):\n",
    "        req.resps.append(x)\n",
    "\n",
    "    if lm.world_size > 1:\n",
    "        lm.accelerator.wait_for_everyone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15393867-64de-46e3-9e2e-2bc2ffc844c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Instance(request_type='generate_until', doc={'input': 'Question: In areas where limestone is present underneath the soil, continued rains can alter the limestone formation. The limestone can change to a highly porous formation that can lead to the formation of caves and sinkholes. Which process is directly responsible for changing the limestone?\\nChoices:\\nA: compaction\\nB: erosion\\nC: faulting\\nD: weathering\\nAnswer:', 'output': 'D', 'subject': 'ARC-Easy'}, arguments=('Question: In areas where limestone is present underneath the soil, continued rains can alter the limestone formation. The limestone can change to a highly porous formation that can lead to the formation of caves and sinkholes. Which process is directly responsible for changing the limestone?\\nChoices:\\nA: compaction\\nB: erosion\\nC: faulting\\nD: weathering\\nAnswer:', {'until': ['\\n\\n'], 'do_sample': False}), idx=0, metadata=('dharma2', 0, 1), resps=[' D'], filtered_resps={}, task_name='dharma2', doc_id=0, repeats=1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reqs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "072198f3-a4e1-45f3-bb6e-0027a20f41ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Question: In areas where limestone is present underneath the soil, continued rains can alter the limestone formation. The limestone can change to a highly porous formation that can lead to the formation of caves and sinkholes. Which process is directly responsible for changing the limestone?\\nChoices:\\nA: compaction\\nB: erosion\\nC: faulting\\nD: weathering\\nAnswer:',\n",
       " 'output': 'D',\n",
       " 'subject': 'ARC-Easy'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reqs[0].doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62bbe454-66eb-42f6-8a26-5e3222f8c404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Question: In areas where limestone is present underneath the soil, continued rains can alter the limestone formation. The limestone can change to a highly porous formation that can lead to the formation of caves and sinkholes. Which process is directly responsible for changing the limestone?\\nChoices:\\nA: compaction\\nB: erosion\\nC: faulting\\nD: weathering\\nAnswer:',\n",
       " {'until': ['\\n\\n'], 'do_sample': False})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reqs[0].arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4560854d-c480-4cbd-add8-2cd344288f57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(' D', 'D', ' B', 'B')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reqs[0].resps[0], reqs[0].doc['output'], reqs[1].resps[0], reqs[1].doc['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfe1dc7-57d4-4766-b526-ecaa4a13bb59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "601b0784-8d9b-43ef-b7df-a83027c6b952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RANK = lm.rank\n",
    "WORLD_SIZE = lm.world_size\n",
    "\n",
    "RANK, WORLD_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d46c349b-e559-45c4-935b-4ac90ad22573",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Postprocess outputs ###\n",
    "\n",
    "#for task_output in eval_tasks:\n",
    "task_output = eval_tasks[0]\n",
    "\n",
    "task = task_output.task\n",
    "task.apply_filters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f0df265-9b22-4196-b77e-1b756f7f6fa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FilterEnsemble(name='remove_whitespace', filters=[functools.partial(<class 'lm_eval.filters.extraction.WhitespaceFilter'>), functools.partial(<class 'lm_eval.filters.selection.TakeFirstFilter'>)])]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task._filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "21a27bb1-1b79-4cc3-a7ff-7205cf952125",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Collect values of metrics on all datapoints ###\n",
    "# # unpack results and sort back in order and return control to Task\n",
    "# TODO: make it possible to use a different metric per filter\n",
    "# Pre-process task.instances to group by doc_id\n",
    "instances_by_doc_id = defaultdict(list)\n",
    "for instance in task.instances:\n",
    "    instances_by_doc_id[instance.doc_id].append(instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6459bfbc-57b2-46cc-89e4-99f03cb2d3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort instances within each group\n",
    "for instances in instances_by_doc_id.values():\n",
    "    instances.sort(key=lambda x: x.idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab20169-d762-411d-a3bc-c9ae731361ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0d85e684-f817-49a9-b0b8-bf63b820b1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove_whitespace\n"
     ]
    }
   ],
   "source": [
    "for k in task.instances[0].filtered_resps.keys(): print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b5bba8ce-60bb-4ebd-8c09-1acce436ff78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'remove_whitespace': 'B'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "req.filtered_resps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efa15dd-30bc-4e87-ae0d-56eef6776166",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f3bb5da1-7879-4b9a-8c8f-19a6e4081a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over different filters used\n",
    "for filter_key in task.instances[0].filtered_resps.keys():\n",
    "    doc_iterator = task.doc_iterator(rank=RANK, limit=limit, world_size=WORLD_SIZE)\n",
    "    \n",
    "    for doc_id, doc in doc_iterator:\n",
    "        requests = instances_by_doc_id[doc_id]\n",
    "        metrics = task.process_results(\n",
    "            doc, [req.filtered_resps[filter_key] for req in requests]\n",
    "        )\n",
    "        if args.log_samples:\n",
    "            target = task.doc_to_target(doc)\n",
    "            example = {\n",
    "                \"doc_id\": doc_id,\n",
    "                \"doc\": doc,\n",
    "                \"target\": target,\n",
    "                \"arguments\": [req.args for req in requests],\n",
    "                \"resps\": [req.resps for req in requests],\n",
    "                \"filtered_resps\": [\n",
    "                    req.filtered_resps[filter_key] for req in requests\n",
    "                ],\n",
    "            }\n",
    "            example.update(metrics)\n",
    "            task_output.logged_samples.append(example)\n",
    "        for metric, value in metrics.items():\n",
    "            task_output.sample_metrics[(metric, filter_key)].append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec6be83-3f17-4f75-8d9f-b5ac71a0c725",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
