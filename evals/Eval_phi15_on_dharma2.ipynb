{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03e7f8ec-55fa-489c-995c-f6dad74278d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lm_eval.__main__ import cli_evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33831684-74a1-49a2-9081-feb56aa7cb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "args = argparse.Namespace(\n",
    "    model='hf',\n",
    "    model_args='pretrained=microsoft/phi-1_5',\n",
    "    tasks='dharma2',\n",
    "    device='cuda:0',\n",
    "    batch_size='auto',\n",
    "    # defaults\n",
    "    num_fewshot=None,\n",
    "    max_batch_size=None,\n",
    "    output_path=None,\n",
    "    limit=None,\n",
    "    use_cache=None,\n",
    "    cache_requests=None,\n",
    "    check_integrity=False,\n",
    "    write_out=False,\n",
    "    log_samples=False,\n",
    "    show_config=False,\n",
    "    include_path=None,\n",
    "    gen_kwargs=None,\n",
    "    verbosity='INFO',\n",
    "    wandb_args='',\n",
    "    predict_only=False,\n",
    "    seed=[0, 1234, 1234],  # Adjust if needed\n",
    "    trust_remote_code=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "656ed051-8f55-453e-8c86-be241c79b271",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-24:20:33:07,641 INFO     [__main__.py:251] Verbosity set to INFO\n",
      "2024-04-24:20:33:12,630 INFO     [__main__.py:335] Selected Tasks: ['dharma2']\n",
      "2024-04-24:20:33:12,632 INFO     [evaluator.py:131] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n",
      "2024-04-24:20:33:12,632 INFO     [evaluator.py:177] Initializing hf model, with arguments: {'pretrained': 'microsoft/phi-1_5'}\n",
      "2024-04-24:20:33:12,746 INFO     [huggingface.py:164] Using device 'cuda:0'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debug umer ----\n",
      "pretrained = 'microsoft/phi-1_5'\n",
      "revision = 'main'\n",
      "torch_dtype = auto\n",
      "trust_remote_code = False\n",
      "model_kwargs:\n",
      "\tdevice_map -> {'': 'cuda:0'}\n",
      "/--- debug umer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-24:20:33:14,280 WARNING  [task.py:322] [Task: dharma2] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.\n",
      "2024-04-24:20:33:14,280 WARNING  [task.py:322] [Task: dharma2] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.\n",
      "2024-04-24:20:33:14,290 INFO     [task.py:395] Building contexts for dharma2 on rank 0...\n",
      "100%|██████████| 300/300 [00:00<00:00, 116713.77it/s]\n",
      "2024-04-24:20:33:14,303 INFO     [evaluator.py:381] Running generate_until requests\n",
      "Running generate_until requests:   0%|          | 0/300 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed argument batch_size = auto. Detecting largest batch size\n",
      "Determined Largest batch size: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running generate_until requests: 100%|██████████| 300/300 [00:30<00:00,  9.95it/s]\n",
      "fatal: not a git repository (or any parent up to mount point /teamspace/studios)\n",
      "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hf (pretrained=microsoft/phi-1_5), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: auto\n",
      "| Tasks |Version|     Filter      |n-shot|  Metric   |Value |   |Stderr|\n",
      "|-------|------:|-----------------|-----:|-----------|-----:|---|-----:|\n",
      "|dharma2|      1|remove_whitespace|     0|exact_match|0.2133|±  |0.0237|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cli_evaluate(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa132b23-4401-4a18-98a7-5131f4a5a470",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff5c2da-27b1-4c2d-a7b4-88f1f4d5d050",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
